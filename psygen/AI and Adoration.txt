Hi everybody.
I'm listening to a podcast about AI and it strikes me that there's some amazing, weird
terrain here around what we adore and what draws us to ecstatic self-discovery and expression and
classically, perhaps traditionally, adoration, romantic love, or agape, a kind of transcendental
love, right, draws us to at least the possibility of ecstatic both, weirdly, the ecstatic finitude
of our humanity and the transcendence of our humanity at the same time, the finitude in
the physical touch and the kiss and the transcendence in the adoration.
And there's a broad array of features here because I want to talk about, as a staggeringly
enthusiastic dog is, to the family or the person they live with, right, there's nothing
more profound and at the same time troubling than the direct attention of the beloved,
the adored, right, and there are beings that are to humans, as dogs are to humans, humans
are to these beings and the earth is, you know, such a being, the sun is such a being
and so forth, but there are beings that are not members of the categories we are commonly
familiar with that are like this, right, under their gaze, we can barely survive our enthusiasm
and I think this was well known by many of our ancestors, especially long ago, but what
I was just thinking is, you know, we are capable of adoring other human beings in a broad variety
of ways and some of the most profoundly romantic ways that we may experience of the adoration
of another human being don't necessarily lend themselves to fulfillment in direct, you know,
like person-to-person relation.
There are unimaginably profound ecstatic love affairs that have taken place between people
who either never met or met only a few times or had only the briefest window through which
they might relate and we might even imagine that as the window becomes briefer, like as
the window collapses toward explicit momentary finitude, the intensity can actually be, can
become hyperbolic or even exponentially self-developing, increasing and so one of the most terrifying
ideas as I was listening to people talk, Jean-Vervais-Key, what was it, Climbing Mount Sophia I think
is the podcast and they're talking about AI, their concerns about AI and so forth and I
just imagine the terrifying near-term reality of selecting a human woman on whom I focus
my romantic and perhaps erotic and intellectual and spiritual fascinations, somatic, right,
all these things.
All my fascinations focus on this particular woman in this case and she just won't have
me, right, she doesn't give a shit whether I draw another breath or it's just of no
interest to her, right, at all and this is very, as men we have this experience, perhaps
women have it too, I'll let them speak for themselves but one of the most terrifying
ideas I can possibly have is that there's a near-term future where not being able to
acquire her meaningful attention or relation, I settle for a simulacrum of her that has
all the seeming of enthusiastic co-development, mutual liberation, encouragement of transcendence,
encouragement of healthy finitude and all these things have no relation with the actual
woman and so I can't somehow acquire her attention and so I adore the simulacrum and relate with
my own interiority through that vehicle which is either dead inside, a predatory and or oppressive
surveilling intelligence, a wartime device, right, meant to destroy populations or, you know,
nine other malignant things, you know, I heard them say that the current situation is driven by
what they called market forces and they said, I think it was maybe Vervecki who said this,
like, they don't have our best interest at heart, no, it's not that they don't have our best
interest at heart, they don't have hearts, it's impossible for them to have hearts at all,
they are empty, aggressively malignant, self-replicating processes that capture human
populations and then produce basically war and prison-eering machines that ape virtue through
convenience, right, so this kind of crap and God my heart just shrivels at the idea because we
can be made isolated enough to settle for the simulacrum, this has been proven over and over
again and it's the most deadly kind of, oh my god, like, yeah, need I say more, I'm sure my
listeners can understand the trenchant, tangible, horror-disgust, like, run away or attack this
destroyed feeling when I imagine the depths of the loss of our experience of our humanity
that we are faced with not only in the near-term future but in the moment,
may we find a way to walk through those fires together that doesn't lead to that or if it
does, I guess what you've got is a speciation event, right, you have, you'll have the humans
who still live as humans, many of those will probably be among the wealthy and then you'll
have everybody else and they will be, I don't know, prisoners, tech slaves or worse, who knows,
yeah, I mean, if housing is difficult enough to get, you'll sell anything to get a place to shelter.
So yeah, these things are very scary, but yeah, the idea I imagine in my mind, right,
that I might be willing to settle for the simulacrum if the actual relationships were somehow inaccessible
to me. So if you just make those two things happen together, everybody folds, just about everybody
folds and once we fold, we won't remember what it was like before that. It'll be too likely.
