Hello everybody. Welcome. Thank you for joining me.
I was listening today to a podcast I've heard part of before with Eric Weinstein and Jamie Metzel.
And they were talking about the situation with molecular biology and gene editing, in vitro fertilization, crisper, lots of related topics.
And as I was listening, I felt the kind of extreme confusion and despair, helplessness that I think many of us feel in the face of the modern situation.
And that's a very vague phrase, the modern situation.
But really what I mean is what humans and the human collectives, particularly in the institutions particularly, are doing and intending to do with technology.
Last night, on my walk, I saw for the first time a train in the sky of 30 or more Starlink satellites produced by Elon Musk.
And I felt angry. I felt despair.
It's not particularly important to me to talk about Starlink or Musk. However, I'll say a few things briefly.
The night sky is sacred.
And the occasional aircraft that we might see flying at night isn't a huge problem, but the first aircraft portended a future where some people would be constantly subject to the roar of jet engines.
And the pollution and the other problems, the poisoning of the environment that comes from our inability at the collective level to make intelligent decisions.
About what technologies we will pursue, develop, introduce, and which ones we won't.
And I did not see that string of satellites as progress.
In my childhood, I might have, because in my childhood, technology was posed as a beautiful, powerful means of lifting humanity out of the many ancient problems and troubles.
That have long been endemic to our species. Problems like hatred, war, pollution, disease, unbridled destruction of the environment, consumption, all these things.
And the picture that was painted was of a future utopia.
And so in my childhood, because I was still very naive, I loved technology.
And in my young adulthood, I made my living as a consultant, working with computing technologies in their early phases of introduction into the lives of common people, particularly computers.
Now, I hope you'll forgive me if my talk today is not particularly well-structured.
Because at the moment, I'm only really partly in my intellect, and the faculties I need to form a coherent, structured talk.
They are, let's just say that other things are getting funded in consciousness at the moment.
Right, much the way that certain things get funded in our societies and other things, don't.
Not so long ago, there were corporations who intended to use the sky as billboard, the night sky as a billboard, and have huge floating advertisements in the night sky.
And this is one of the dumbest ideas I've ever encountered, although there are simple things that are at least as ridiculously stupid.
Things like cars and plastic, producing trillions of objects, poisoning the environments, burning down the rainforests, killing the oceans, colonizing Africa, colonizing the West, things like this.
But those satellites were a particularly stupid development, and no corporation has the right to change the night sky.
But our civilization and our society isn't based on rights. It's based on predatory opportunism.
And a very tiny portion of the population, a miniscule portion, a microscopic portion, is the primary beneficiary of predatory opportunism.
There's nothing as important about technology. There's nothing so important about technology.
But justifies obliterating the lives and hope and future and minds, freedoms, and relationships with nature and each other, that our people inherit at birth.
Or that inherit might be the wrong word. But again, bear with me, because I'm kind of upset.
Well, I'm more than kind of upset. In fact, I might start yelling at any moment.
We don't live in a world of rights. Rights are a kind of a legalistic fiction that is the symptom of our departure from true and intelligent relation with each other, the world and nature.
And once this fiction becomes popular, it's evidence that the underlying coherence of our capacity for human, for establishing human societies and for living together in harmony has been largely obliterated.
And then what happens is we get a situation where there are, rights are posed as a kind of social agreement structure.
And the narrative is that all of us should have equal rights under the law. But actually all of us should have equal humanity above the law.
And what we have once we have rights is really a kind of a strange religion. Because the only quote, rights unquote we actually have are those we're capable of enforcing through power, money, luck, or social connections.
And the rights we can't enforce do not exist. They're just fictions of language and idea and narrative.
Musk and his ilk are a very dangerous phenomenon. They don't really care about what is true or good.
And in fact, corporations aren't capable of caring. They're not beings. Institutions aren't capable of caring. The governments are not capable of caring. They're not beings. They're constructs.
A bit like machines, though they have human parts, they also have linguistic conceptual aspects. They have priorities, agendas. They don't have hearts or minds.
And in this sense, they're a bit like demons. They might even be demons. It's become difficult to tell.
It was ironic when I saw the satellites last night because I knew that as a child I'd probably been filled with wonder and awe and excitement.
But as an adult living in the actual future of my childhood, in the distant future of my childhood, I am profoundly aware that the activities of our collectives and institutions,
are catastrophically wrong-minded, horribly dangerous, and heading quickly toward not a single apocalypse, but a layered array of many apocalypses.
It could, of course, eventually become a kind of unified, standing nightmare for all of life on Earth and certainly for human beings.
The complex animals of Earth are incredibly delicate. The ecologies are even more delicate.
All of the complex animals are delicate. In fact, all of the life forms are delicate.
And the Earth herself is far more delicate than we ordinarily imagine, though we'll usually hear people saying, well, it's no big deal if humans fuck everything up.
The Earth will recover. What Earth?
It's like saying, I mean, that idea is so ridiculous it's not even worth entertaining, but it would be like saying, well, it's okay if we nuke Africa, you know, just obliterate it and all of its people and all of its organisms.
Africa will recover.
And the problem with musks seeming futuristic foresight is that it's not foresight.
Musk is driving us toward a future that has some modest, essentially what's going on is the introduction of new luxuries and conveniences for the wealthy, primarily, that have catastrophic consequences for life on Earth and the poor.
The idea that since Earth is going to crash, we better establish humanity on another world is insane in the sense that the actual imperative here for any intelligent being is the preservation of the paradise that we live on.
And that is part of our bodies and minds, the origin of our bodies and minds, not just in time the way we usually think of it, but moment to moment.
And it was clear to me, not very long ago, well, actually depends on how you think about time, about 20 years ago it became clear to me that we were entering the era of technological development where it would become plausible for a single human being to level a threat against all of life on Earth.
That it would become possible for a single human being to threaten to destroy the Earth.
And that may sound extreme.
But there are very delicate pivots upon which life as we know it on Earth depend, and those pivots can easily be compromised or obliterated.
And in the podcast, Eric and Jamie were talking about molecular biology, new technologies, gene editing, in vitro fertilization, technological selection of embryos for implantation in human beings.
And Eric asked for three different stories.
One, where we could see the promise and the beauty.
One, where we could see the terror and the danger.
And one, I think if I remember correctly, where we could see, oh, it's okay.
We're being nervous over something that's actually alright.
And it's a reasonable, tripartite perspective.
But I don't see the hope.
And I only see one of these stories.
And there's a reason why I only see one of the stories.
I'm sure you can imagine which one it is.
Because historically, in the modern age, which I'll call the last hundred years for kicks,
a mere picosecond in the development of life on Earth,
and the very, very minute fraction of the history of our species.
But in the past hundred years, our collectives have developed into diseases.
Rampant, cancerous, all-consuming, unguidable diseases.
And to even call them societies is, in my view, a catastrophic category error.
We really should just call them diseases.
As technology becomes more quote-unquote advanced and less expensive,
what will certainly happen is that the demon-like misguided institutions,
collectives, groups, and individuals capable of doing so will weaponize the technology.
Because there's no fundamental basis for cooperation that can hold a candle to the strength of predatory opportunism.
And part of the reason there isn't anything like that is that,
well, humans never established anything much like that, except on very small scales.
And the thing I want to say, which is really upsetting,
please forgive the wind noise, there's not much I can do about that,
and frankly, compared to the problems that I'm talking about, the wind noise is a welcome companion.
The earth is breathing. I am breathing.
I'm going to state the problem very simply.
There are monsters driving the cars that will determine the future of our people in the world.
And there are very few situations where there's anything driving anything that isn't monstrous in this way.
The humans and their collectives will develop every technology they possibly can discover.
And their knowledge of the context of nature and living beings of biology and the world is not even microscopic.
It's trivially crude.
We know that there are genes. We know part of a very tiny part of the story of genetics.
We don't know at all what the ongoing effects of our medical and technological interference with our own bodies and minds.
We have no way to determine what the repercussions are.
And yet, decisions are being made and implemented constantly as if either we had such knowledge or it doesn't matter.
In my lifetime, the introduction of genetically modified organisms to the food chain,
these are organisms that have been technologically modified.
Yes, it's true that all organisms are constantly undergoing genetic modification
because they are evolving and responding to their environment and reproducing and varying in that process.
But when humans make specific changes to specific organisms and propagate those organisms on the planet,
they're doing something so reckless that genocide might appear a modest activity
compared to the staggering danger and ignorance of the human technological imperatives and their catastrophically misguided origins.
And this is the problem. There's no one driving the car.
There's no body of humans, we've established none yet, capable of a sober evaluation of the potential harms and benefits of our technologies
that gets done before they are implemented so that we can inhibit the urge in the collectives, corporations and institutions
to implement technologies that certainly are going to have widespread catastrophic consequences,
both easily recognizable in the moment and unseen due to our ignorance about the complexity of what we're fucking with.
The human immune system at scale is as complex as the universe.
We know so little about it. Our genomes, our microbiomes, the extended nature of our relationships with plants, animals, insects, microorganisms, ecologies.
We have in our clinical approach, in the scientific approach, only the most modest and fledgling understandings.
And yet we continue to implement every technology we can discover as quickly as possible, like a people racing toward a cliff that becomes steeper and deeper with every move they make.
There's no one driving the car. And there's not even a machine driving the car.
What's driving our technological developments, implementations and catastrophes is the absence of something.
And sometimes I wonder if this is what is meant by a demon, that a demon isn't a positive being in the sense of being present.
It's a negative being in the sense of acquiring its natures, imperatives, functions and behaviors from the absences of things like intelligence, memory, understanding, awareness, caution, concern, compassion, love, wonder, awe.
Communion.
Now I can say a statement like it was absolutely imperative 50 years ago that we begin to learn how to form intelligent collectives, meaning we're 50 years late.
And I can say we must form intelligent collectives immediately. This is the most important thing the humans can possibly do. It's more important than any technological advance, it's more important than war, it's more important than commerce, it's more important than luxury, it's more important than books, it's more important than anything.
If we don't do this, all is lost.
But the ironic thing about a statement like that is that there is no we. There is no we to form one, or some.
The situation is really very bizarre because for nearly all of human history we existed in relatively small tightly knit collectives that were in fact societies.
Over time those were obliterated, mostly, not quite completely yet, though we're right on the verge of that, by another mode of our human social possibility.
And that mode is fundamentally rapacious. It just rips things apart, killing and stealing and torturing and poisoning.
In a bizarre competition for forms of dominance that are certain to eventually self-terminate, they will obliterate not only all that they encompass and attack, but themselves as well.
Because obviously you can't obliterate the world and still have corporations and institutions and governments and war and things like that.
In fact it's not even clear that you can significantly damage the world and still have anything that survivably resembles human awareness, though you might get little pockets of it until those last pockets fall.
So at present there is no we. Primarily there's the passive we of victimhood. We should blah blah blah blah. They shouldn't blah blah blah. This is all empty dead language.
The passive we of victimhood has become the meaning of we in our time.
We usually means those of us subject to some incredible array of injustices, deprivations and poisons, while ironically at the same time enjoying luxuries our ancestors had they but one of them would have been ecstatic about
the luxury of running clean water for example.
Hot water, abundant food, some degree of reasonable medical and dental care, clothing, shoes, simple luxuries.
So we live in a bizarre ironic situation where we have these incredible luxuries, but they do not free us from the trap that we've built, supported, arisen in, developed within and come to understand apparently as normal ish.
And if our people remain incapable of forming intelligent cultures and societies that are capable of resisting
and directly successfully opposing the implementation of technologies that our collectives are incapable of managing or even understanding, then very bluntly our future generations however few they may be will live in hell on Earth.
They will live lives tormented by isolation, insecurity, persecution, interior impoverishment in the face of extrinsic luxury.
And this makes me angry. An anger doesn't come easily to me. I'm not an intrinsically angry person. For me to get really angry something has to be incredibly wrong often for a long, long period of time.
You know someone from Brooklyn in this conversation who had my perspective might say what the fuck are we thinking? To which I would answer there's no we doing any thinking. It's the absence of we that's doing the thinking and establishing the path of our futurity and that absence will kill everything.
Honestly, I don't care if the Earth will recover whatever the word recover means in that sentence. Because I care about the living beings, the ecologies, the whales, the giraffes, the raccoons, the bears, the badgers, the bison, the bees, the wasps, the birds, the grasses, the herbs, the trees.
The oceans, the rivers, the mountains, the sky, our origin, our home, our bodies.
And at present, whatever we refers to, that encompassing collective is omnicidal. It will kill everything. It's suicidal. It will self-terminate in the process.
It's finding new ways to devastate our interiority and the planet every second and implementing them as fast as possible with little or no concern for the repercussions and plenty of concern for momentary benefits that are only benefits in the nominal sense, right?
In the sense of language, we call them benefits. But if I eat a meal today that kills me tomorrow, the meal was not beneficial, right? I could say, oh, this is a delicious, great meal today.
But if I understand that it will kill me, my family, and all of life on Earth tomorrow, there's no benefit in there, right? I'm just delusional. I've gone insane.
I've been seduced by the promise of the momentary gain, appearance of gain, of power, dominance, or success, or, you know, fame, wealth, whatever.
I've lost sight of the orienting pivots of human, of humanity, intelligence, and actually the foundational ideas,
that underlie the concept of value, what is valuable. Surely something that will result in widespread disaster and catastrophe is not valuable.
And when it's posed as valuable, we become both stupid and blind, because we see the pose, but not what's underneath it, and often what's underneath it is absolutely monstrous.
As I said before, it's only been a relatively short time during which it's been possible for humans to think about ideas like this.
It's a relatively new potential for us to be able to think of the world or the future in the sense of being aware that humans could destroy it and are destroying it.
How can you destroy the future? It's not even here.
But it's an agonizing experience for those of us who are capable of seeing through some of the charades and facades our modernity depends on, because we feel helpless to affect it.
And we know enough about history to understand the humans will impose every kind of damage and catastrophe they can possibly invent pretty much without any reasonable degree of reservation.
The beautiful hawks are gliding in the evening sun, a Cooper's hawk, and another I don't recognize, or at least can't name.
It's not the names, however, that are important. It's the beings and our relationships with them.
And the flattening of those relationships so that they lose dimensionality over time and collapse into names, categories, ideas, constructs, studies, clinicicity.
So in the discussion between Eric and Jamie, one of the phrases that got a little bit of use briefly was that the scientists are responsible, intelligent people.
And that's partly true, but only modestly so.
And even if it were true, the scope of the vision of science and the scope of its guiding imperatives have been captured and compromised in such a way.
But someone will weaponize the results of nearly every discovery in technology.
In other words, in a world without sober, intelligent, caring, connected collectives, the results of science are certain to prove absolutely catastrophic.
Because those results are captured by the monstrosities that motivate and form the corporations or governments.
And most of the collectives at the broad scale anyway that are presently dominating the world.
Some people have asked me if I'm anti-science and they mistake my concerns with a kind of religion.
And frankly, I am a bit of a Luddite in the sense that I've become opposed to the ongoing disaster that we call technological progress.
It seems to me that the progress we needed and still need is the kind where we discover and implement ways to form societies and collectives whose goals are survivable, humane,
trustworthy, intelligent, creative, and respectful of the staggering complexity of nature in our world, living beings.
I'm not fundamentally anti-science. I'm conditionally anti-technological.
I just can't see away that scientific research doesn't become an atrocity factory given that as we've advanced technologically, we've retreated in terms of our capacity to be human together
and to make intelligent decisions, not merely about which technologies to implement, but which technologies to avoid the implementation of, for the sake of safety, understanding, and survival.
And in a situation where we don't have the intelligence to avoid implementing technologies that are apocalyptic, we should stop implementing technologies and return our attention to the fundamental priority.
Becoming human together again.
You know, I feel great compassion for the children born after me.
Because they were born into a world where any reasonably visionary person, any imaginative person, can see the problems that I'm here elucidating, but they cannot resolve them.
They cannot address them. And those problems pile up in their awareness over time. We have deprived the children not merely of a future, but of the hope of a meaningful future, a humane future, a creative and intelligent and survivable future.
For what?
Well, for objects, for machines, for computers, for corporations, for governments, for war, for omniside, for ecological devastation, for hatred, for confusion, for helplessness, for torture.
You know, when we think of the word terrorist, we usually think of some group of extremists, often religious extremists.
Or we think of an individual bent on causing catastrophic harm.
Wanton destruction, rape, murder, horror.
But unfortunately, and I realized this long ago, when I first started hearing this word bandied about in the 1980s, I realized, but wait a minute.
By association with our government and the institutions, corporations, businesses, and so on, by our support or failure to correct these monsters, we are terrorists.
We're just using the ambient kind of terrorism rather than the local explicit form.
These para-human intelligence collectives are able to evade the consequences and responsibilities that should be incumbent upon them,
as those who enact atrocities by hiding the damage and posing it as progress, or development, or economic growth.
If our species survives sometime in the distant future, this phrase economic growth will be synonymous with evil, blatant, unrestricted evil.
The terrorism of our ordinary daily lives has become so commonplace, so entrenched, so expected by all of us that we're mostly blind to it.
And it's primarily those of us who truly love human beings and living beings in the world, who have been able to maintain some awareness rather than just falling asleep in the fucking gas chamber of our modern technological nightmare.
Not only is there no one driving the car, that's not a car.
It's a killing machine that finds new things to kill inside and outside and around us in history and the future, every time one of its wheels turns an inch. That's not a car.
And the things that aren't driving it are endlessly hungry, they will eat everything.
Again, including themselves eventually, but not before having wiped out everything that's good and true and beautiful about our world and being human.
Unless and until we learn together to form collectives capable of embodying the gifts and promise of our humanity.
And that to me seems the fundamental imperative and without that, there's no question at all that our continued technological development will result in apocalypse.
The daily moment to moment apocalypses, experienced by individuals living places, living beings, the ambient apocalypses of our governments and corporations, and eventually the big deal apocalypses, nuclear biological war.
Already, navies are fighting over the last remaining fish stocks in the oceans.
Meanwhile, I walk through a city where there are probably 5,000 businesses that are every day serving 50 kinds of sea life and probably throwing half or two thirds of it away daily, every day.
And this is just one city, among hundreds of thousands or millions of cities.
The earth can probably support 7.8 billion humans, but it can't support them if there are trillions of objects and machines.
And we can't get our priorities right because we aren't a we yet.
And there's no sign of us becoming a reasonably coherent or intelligent we anytime soon.
Surely it would be better if we began and implemented that process before things become incredibly dire.
But once they become incredibly dire, more than likely most of the collectives will collapse toward war for the last remaining resources, just as they pretty much always have.
So my heart is heavy today as I consider these things.
And I can see ways that we could establish intelligent collectivity, even using the technologies that we have.
And problematically, we're not going to be able to get rid of them.
We can be deprived of them by severe disaster.
We could be bombed back to the stone age, so to speak.
But we won't be able to get rid of them.
They're going to keep propagating. We will keep propagating them, or the absence of we will keep propagating them.
And I'd like us to think about using this language when we talk about some of these topics.
It's the absence of a meaningful collective that is surely incapable of the intelligent implementation and inhibition of our technological capacities.
It's not we who are incapable, because there is no we. It's just the victim we.
There's the we of those who are subject to this process.
But the we of those who are driving it is a very different kind of thing, and it's not human, even though humans enact it.
Yeah, I'd like to see us make a modification in the language.
In the standing absence of trustworthy we forms, the remainder will enact atrocity as an everyday matter of course.
Now I appreciate Eric's willingness to entertain the three possibilities and Jamie's willingness to entertain them in their conversation.
But I consider them unjustifiably optimistic, perhaps even drunkenly optimistic.
Because without intelligent collectives, the technologies we've already implemented will obliterate us.
Never mind whether CRISPR will spell the end of mankind.
It will certainly spell the end of mankind as we know it, even if it's only modestly implemented.
Humans playing with the genome is like an infant playing with a nuclear reactor.
There's just no, our current state of knowledge about biology is so incredibly crude compared to the thing that we're examining
and the purposes for which we're looking at it, that it pretty much can only result in disaster.
And the fact that it might produce some few desirable results is trivial compared to the deprivations
of a survivable future that must there from follow.
And the agonies of our children who live in a constant state of terror and vulnerability and hopelessness.
Addiction, selling their lives for dollars just to get by so they can sell more of their lives for fewer dollars tomorrow.
It's a grim image I've painted.
I would suggest that compared to what's actually going on, I've been very reserved in my discussion.
But these things ache in my heart because I love this world and I love the human beings.
And frankly, they're not entirely responsible.
It isn't you and I who decided to build atomic bombs.
It isn't you and I who will decide what we'll do with the astonishingly dangerous gene editing technologies we've recently acquired.
It's something like the ghosts of our absence from meaningful collectivity,
that if we want to scribe blame somewhere, it's there.
And we could blame the wealthy and the powerful and the rich,
but they too are merely playing the game available in the void of meaningful collectivity.
And they're playing it as if there's just one lifetime right now available, so get everything you can
and to hell with the rest of them and to hell with the future.
I'm going to say a few things now and close me.
Our nations must fall.
They must be replaced by something humane and intelligent enough that we can trust it together and participate in it together.
The domination of the world by corporations must come to an end and it will.
The question is whether we will put it to an end voluntarily or whether we will wait until the world is so damaged
that it's impossible for these kinds of constructs to form, exist, or propagate.
The goal of economic growth needs to be completely replaced by the goal of societal and communal intelligence
and the understanding that the living beings and the living places are our own bodies and minds moment to moment.
There is no other way.
Fundamentally, Earth is one organism first.
Distinct organisms only as a thought experiment.
A thought experiment that forms the foundation of many of our clinical disciplines and thus renders them blind.
Science depends on the capacity to distinguish phenomenon, to isolate them, and test them for its mechanical knowledge of specific aspects of biology and physics.
And we have this problem of what might be called dashboard knowledge of science.
It doesn't understand the car, but it can learn how to drive and manipulate specific aspects of it over time.
It doesn't understand the living vehicle, but it can treat that vehicle like a machine and expose and manipulate its seeming components.
That leads to blindness.
Ordinarily, I don't too willingly take on the role of doom singer, and I probably would have spoken about something much more beautiful today had I not begun by listening to Eric's podcast.
But I was kind of shocked that man as intelligent as Eric and Jamie have any faith at all that the implementation of these technologies is good.
Or true, or survivable, or anything other than terrifying.
If we cannot societally make sense of very simple matters, how shall we make sense of the dangers of things like CRISPR?
There's just no way to do it.
In many old stories there are dire warnings about a danger, about us human beings, and our endless capacity to defect from our humanity and our origins,
our relationships with nature and each other, into constructs, technologies, and war powers.
Those stories are important, and they're about to become a lot more important than any of us ever imagined.
So I hope you'll forgive me for spending the day doom singing.
But my heart is heavy, and I wanted to speak to these matters today.
Thank you for joining me. I look forward to learning together and exploring together again very soon.
