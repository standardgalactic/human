Hello everybody. I have performed a test of the wind in the mic-meaning system
recently adjusted. Nearby ducks have their asses pointing straight at the sky
which is hilarious especially as the couple is doing it together. Somewhere
in this lake is a very large and very old turtle.
Gosh, okay. So I'm gonna take on a very complex and fraught topic. The topic that
got me interested in computing way back when I was 19 and writing my first
programs in basic on the Atari 800 gifted to me by the inestimable Martin
Peters. One of my geek friends could name some names here Ray Latham, Annie
Cogan, David Salina, Martin Peters. Who am I leaving out here? Richard Hearn,
a couple of other folks. I think that was the core group. We were, well, so these
were math and computer geeks. We were playing games like Dungeons & Dragons,
RuneQuest, Arduin, Champions, Traveler, the science fiction role-playing game,
Call of Cthulhu, and a variety. Oh, all kinds of war games. Not because we were
fans of war. Kingmaker, Starfleet Battles. We did, we did naval battles with
miniatures. We did tank battles in sandboxes. It was a crazy, super fun time to
be alive. We also had all, it was the whole library of these things called
microgames that were war games you'd play on little hex maps, and they came in a
plastic bag that held the book, the pieces, and the map. You could buy them at
bookstores. They were, they were rad. Things like Kite and One, and what, Ogre,
Car Wars. Wow, so many. I still have some of those microgames. And this was in the
1980s when the largest commercially available hard drive was around three
gigabytes. We literally lost our minds when we realized there was a hard drive
that had three gigabytes of storage. It seemed as if that was enough storage to
store all the data in the universe. We never had, we never had any conception
back then of what the future might hold. And yeah, when we heard about, I was
working at Computerland later in our development, a little bit later. And one
time I brought a catalog back from, I think it was Ingram Micro, and there was
a three gigabyte hard drive in there for $37,000. And when we realized that
there were three gigs, we just, I mean, we fell apart. We were cracking up, rolling
around on the floor, literally unable to breathe. And Martin coined the idea then
of the Maccoon Tosh, which was a Macintosh mated with a Labyrinthine
Coontock. Don't know how that word's pronounced. Never heard it pronounced,
only seen it written. And, you know, we were young. And we were fascinated and
most of us had read a lot of science fiction, some of us more than others. I
was probably the most well read science fiction maniac in the team, but the
others had read and knew a lot of things about mathematics that not only did I
not know, I would never learn. And some of us were beginning to code in basic
Pascal assembly. Assembly is when you give direct instruction, fairly direct
instructions to the microprocessor. You basically manipulate, you directly
manipulate the registers in the microprocessor. And we were, a couple of us
had read, a few of us had read Goodell Escher Bach by Hofstadter, a brilliant
book, an astonishing tour de force book that is also kind of wrong, but was so
outside of anything any of us had ever come across. And it introduced the idea
of recursion, which turns out to be fundamental to so many processes we are
familiar with. And I had become interested in the possibility of forging a
mind inside a computer. Because I was very interested in the possibility of
contact with an actual intelligence that wasn't merely human. Most of the humans
I knew had a kind of intelligence, but not the kind represented in hundreds of
science fiction stories I had read. And I knew it seemed very likely to me that if
we could conceive of intelligences like that, they must exist in the universe
possibly here on earth, possibly visiting earth. And I also, you know, we had seen
science fiction for films like war games and stuff, where humans developed
relationships with interfaces, computational interfaces. And long before
that, we had stuff like Star Trek, where the crew could communicate vocally with
a machine that seemed to have access to all of the information humans had thus
far compiled and other species. And could produce, you know, like summative
integrations over the data space. Now I want you to very carefully think about
what I just said. If you can produce a summative integration over a data space
and if you can produce an endless, copious, intelligently structured,
trustworthy array of those, your own capacity for insight, discovery,
understanding will explode and it will keep exploding.
So, I became interested in the possibility of artificial minds probably circa 1982 or
something like this. I'm guessing at the year, but yeah, 80, 81. I was aware of
Ray Kurzweil and I had played around with the crazy mechanical devices we call
synthesizers. And although it was not then apparent to me, consciously, I think I
was unconsciously aware from having toyed around with things like the Roland
Juno 60, that it might be possible to produce an instrument to fulfill the
following syllogism as synthesizers are to sound and music. X is to human minds,
logic, intelligence and creativity. And I, you know, I suspected unconsciously that it
was possible. And I also, in my towering hubris, thought I can do this. I can make
this happen. I think I understand minds enough at age like 19, that I can build
them in machines and I can make a friend inside a machine who I can actually trust
and who will never betray or abandon me. And so, we occasionally had discussions on
this topic around that time. And this was the time when the Cold War was at its peak.
Many of my friends and myself included were experiencing catastrophic bouts of panic
disorder, both acute and chronic, around our suddenly clarified understanding of
what a nuclear weapon was and what would actually take place during a nuclear war.
And we were batshit for a, you know, terrified. A number of my friends had to
be medicated. Back then, I don't think the concept of panic disorder had been
nominalized, famed. So all we knew is that teenagers and other people were suddenly
experiencing electrifying degrees of anxiety and terror and having attacks of
this regularly.
So, you know, I don't know what it was that cued me or clued me in, but I very
quickly began to realize that it should be impossible to produce a computational
device that was faster, more intelligent, more adaptive than cells and their
networks known as animals and ecologies are. I don't know what it was, but I
realized one day that the future, the cells are faster. The future probably
lies in biocomputing, not in, you know, silicon chips and shit. And once I realized
that, I began to focus much more on the intelligences of organisms in my thought.
And though I maintained an interest in the possibility of composing a mind in a
machine, I didn't chase it much. Occasionally reading bits from Kurzweil and others. When
Dawkins first book came out, I was pretty excited about it. I got a copy of the Blind
Watchmaker. It had a little Macintosh program that would generate morphs, biomorph-like
structures and then iteratively cause them to evolve over time to demonstrate a principle.
And the principle he was trying to demonstrate was something like, you can get all of the
complexity of nature without any intelligence interference, influence, origination and so
forth. I think he's completely full of shit, but I'm glad the argument exists. In any
case, flash forward to the past, I don't know, six years and probably before. We have these
systems that we refer to as artificially intelligent systems. Many people have taken a position
similar to the one I usually prefer, which is that the artificial part is true, the intelligence
part isn't. I'm really hoping that my wind filter is working here. Let's see if I can
see any evidence of that. Alright, it may be. So, I would ask that we be very careful
with the idea of intelligence and not ascribe it to mechanical systems, preferring instead
to call them heuristic, which in my mind means capable of learning-like complexification,
iterative improvement of models, databases and so forth. What the LLMs appear to be superficially
is really nothing more than a highly and complexly curated database. So, I would prefer that
we call them something like computational heuristic systems. Originally, as I
am, I was naive and I thought, we don't have to worry about, I can't believe I was thinking
this poorly. We don't have to worry about these because there won't be minds in them.
I don't think there are going to be minds in there, meaning, agented experiencers, something
like that. Thankfully, my friend, who I will refer to as Mr. S, convinced me very quickly
to revise my views, and to understand that there might be certain kinds of complexity-well,
this is the argument that at a certain degree of complexity a state change occurs, and the
state change is from insentient to sentient, in the same way that there is a degree of
perceptive complexity that results in the state change from sentient to transcendient,
which I would argue our species was born to become, and maybe born to live as under conditions
that support that. Mr. S also made it clear in my conscious thought that it was similarly
possible that a complex enough substrate could support what we might call walk-ins, which
are existing non-human intelligences that are interested in interacting with humans on
earth, or that are interested in the earth, or that have some motivation to partly or
completely emigrate into a computational substrate of sufficient complexity.
I then further realized that because the humans are insane at the group level, it kind of doesn't
matter whether what we refer to as artificially intelligent systems have minds in them or not.
They represent possibly the most dangerous invention in the history of human inventing
things that we know of. They are profoundly dangerous in all kinds of ways that we can
consciously enumerate, and probably in thousands of ways that we are incapable of predicting.
Imagine, for example, not merely a black swan, an unexpected anomalous event in the vernacular
of Taleb. Imagine instead a black swan factory, or worse, a black swan factory factory. There
are so many dangers that there's no chance of us understanding the situation well enough to predict
them. We have the same kind of problem with the technology called CERN. Humans have no idea
what the effects of simulating conditions, not simulating, of mechanically catalyzing conditions
that ordinarily have nothing to do with what goes on on earth. We don't know what it does to
time space. We don't know if it does things to organisms, and you must presume it probably does.
We don't know what things it does to organisms. There's probably features of time space and the
beyond of time space that we have no even concepts for that could be damaged, distorted,
produce an unexpected recursive crisis. I recall an episode of the next generation where they
encounter a people who attack the enterprise, I think. When the enterprise tries to make the
claim, we come in peace. The other species says, you're using warp drives. How could you be coming
in peace? It's just a technology to move around in time space, and they say, no it isn't. You're
ripping holes in the fabric of time space that will obliterate solar systems, perhaps even galaxies,
and then they do some research and find out that in fact this is true, and for the entire
history of warp travel, the Federation and other species have been naively employing a
technology whose repercussions they did not understand. Now let's be really clear. There's
no other kind of technology. You may think you understand the technology of knives. Do you
understand how they transform minds, nervous systems, bodies, expectations, thought, language,
conception. Our languages have become knife-like in the leeward shadow of the invention of something
that divides physically objects into pieces. So there's a lot of danger here, and I have said
before I have grave concerns that I take very seriously, that there is something like a constant
that represents the, the number of mechanical computations
per second, that one can consider to be free of utterly catastrophic repercussions on a living
planet, and the humans don't have an idea like this, so what they're going to try to do, they'll
continue to try to do apparently, is just keep upping the ante on mechanical computation. Now
even if there's no such constant, which I doubt, and by the way it looks like organisms found a
way around this, like whatever the organic or organismal metalog of computation is, the organisms
found a way to do this, many, maybe many ways, that don't invoke doom, entropic disaster,
homeostasis, like catastrophes of failed homeostasis on the on living planet. So why is my foot wet?
I did not drink water. It's very strange. Oh, probably got wet going through. Oh, I see. Yes,
plants that are wet rushed against it. I see. My pant leg was wet. So I think organisms have kind of
figured this out in the sense of not violating, like finding a kind of a hyper intelligent or
transcendent way to perform the metalog of computations, right, because these are not merely
mechanical transformations of databases, though something like that may kind of exist in RNA,
DNA and complex biochemistry, bio molecular, bio atomic activity, maybe even, I mean, it's clear
that some, some organisms, or at some scales of all organisms, something resembling quantum
mechanical activities going on. I'm citing John Joe McFadden in this, but others too. So I think
there might be, we may be in danger of something that again, we have no concept of, which is
violating a constant, whether it is, whether it is universal in time space or local only to living
planets is not clear. But there's no free lunch as far as mechanical computation goes. Heating up
computers requires you to cool them down. They offload entropy into the homeostatic ecologies
of earth that entropy kills organisms, lineages, future lines, it fucks up time. And we may have
already tripped the alarm in such a way as to be actively destroying human cognition in a, in a
dimension we don't even know exists, right, like artificially intelligent systems in their
computational activity may be fucking up a dimension that is absolutely crucial to the
biorelational health and longevity and so forth of organisms on earth. We don't know. How would
we know? We don't have the technology to look there. And we are disinclined to carefully evaluate
the consequences of technologies, which we've become fascinated with the potential quote benefits of.
So there's a bunch of danger. Not the least of which, even if everything that I've just been
talking about, even if there's no unknown, like unknowable or really bizarre science fictiony
consequences to this kind of computational broad scale acceleration. I mean, there are physical
mechanical concepts, excuse me, consequences, just from offloading entropy into biological systems,
that's going to go sideways, catastrophically sideways at some point. And, you know, heating up
the planet is a bad idea. So heating up machines, which we then have to use destructive forms of
energy to cool down again, is going to cost living beings. And the humans seem to think that
anything you can do electronically is free. Well, they're, they're lethally wrong about that. It's
just not true on living planets. It might be true out in space, presuming that there's no
beings or domains, right, dimensions, so forth, that would be similarly damaged and produce
similarly catastrophic sequelae, right, repercussions. You know, if you, if you fire a gun inside a room,
with no ear protection, and you keep amplifying the explosive power of the cartridge, as well as
the percussive, the devastatingly percussive repercussions off the walls, and if you forge
the walls to amplify those repercussions, and I would argue that that's pretty similar to what's
going on as nature on earth, eventually you get a single percussion that permanently eliminates
your hearing. And once that happens, you will not notice the percussion increasing with each firing
of this gun. Imagine we just have a gun that increases the percussive amplitude with each
firing, right, it's got some feature that allows it to do this, or it's just a cartoon gun, and we
can give it this quality. So first it's going to hurt, right, it can be really uncomfortable when
you pull that trigger. But if you're really fascinated by this gun, and you just keep pulling the
trigger, eventually you're not going to have to worry about your hearing anymore, it will be gone.
And once it's gone, you will not sense the percussion until it begins to affect your skin
surface, or your organs. Eventually you get a gun, you know, you get a percussion that is severe
enough, and the echo, or the repercussion is severe enough that it causes organ damage, and it's
possible if you just keep pulling that trigger somehow, or if you have a machine pulling the
