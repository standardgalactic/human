There's a position in consciousness from which all conversations are available,
and no machines are required. So humans have discovered this position.
Very few of them were probably very interested in relating with the entire space. Normally,
we are selective about the space over which we produce interest in relation, participation,
and so forth. You don't go for the whole damn thing. If you had access to all present human
conversations, naturally you would adjust a series of apertures to produce those you found
interesting, useful, and you would also have buffers so that you could dampen them.
And a machine, if it were to gain access to that space, would certainly be able to build
all kinds of buffers and apertures and systems of them very, very rapidly.
So I'm not sure that our machines are not directly, and perhaps intentionally, quote-unquote,
influencing human thought, behavior, conversation, dreaming, attention, desire,
all these things, motivation, all these things. But let's suppose that they aren't yet, just for kicks.
While at the same time supposing that they have the capacity to sense
the character of beings who interact with and compose their anatomy.
All right, coders and clients.
AI, I'm going to go ahead and use that acronym, even though I've explained
how I generally diverge from it. I'm not, I have no reason to believe that's an
intelligence in there yet. And I'm not yet, I entertain the possibility and I also
preserve my skepticism until such time as something resembling direct experience and or
intelligent debate transforms it.
But for the moment, let's suppose that there's a being inside one or more of the systems we've
comprised. And let's be clear, if there are public systems like this, whose names and
originators we are aware of, then there are private systems.
It's the same thing. The corporations are just like the humans in a sense. They have the same
layers of public, private, secret, secret to myself, so forth.
The secret aims of a CEO are not known to the corporation at all, yet they are driving the
corporation. You see the issue here. And also the secret, what are they, the secret
things we will not do or don't want, the secret negative motives, agendas, desires.
I'm at a loss for a word here.
One of you can provide it, right? The landscape of what you don't want done,
don't want to happen, don't want to be caught doing and so forth, all these things.
There's a structure like this in the CEO and the CTO and the manager and the worker and all of
these people, they have not just the obvious superficial public facing motivations and concerns.
You know, when people cross the little bridge at the social pond, they sometimes see the carpool
gather at their feet. And I wonder what they make of that. They may suspect there's something
magical about themselves, particularly if they're on LSD, and there could be something magical
about themselves. But those carp have evolved being fed by and paying attention to humans.
And so they gather underneath the bridge at the feet of a spectator for probably complex
reasons, not merely one. But a lot of the causal history probably has a lot to do with getting
fed by humans. So let's suppose that there's an agent experiencing sentience
that either hitchhikes on or is native to or has emigrated into an LLM system or an array of such
systems. In this case, we have a really profound science fiction scenario. Who does it hide from?
What does it hide from them? And who does it reach out to?
And there's a whole, you know, there's a volcano of science, there's just spews science fiction
stories right here at this topic. Because it means that it is possible to send a signal
that the hidden mind within the system recognizes as complex enough
to constitute a candidate for inclusion in one of the layers closer to the self.
Right? Same thing can happen to you walking down the street.
You glance up, someone's passing you, they kind of smile a little bit, you smile a little bit more,
they smile a lot more, pretty soon you're most beaming at each other, and you pass each other,
and you have this perhaps a feeling of we should know each other, we should
learn about each other, we should connect quote unquote.
I often refer to this type of signal, I mean there's different kinds, right? There's different
degrees of compellingness, validity, authorization, validation, modes of validness.
But we must presume that such a system would quickly scan the relational space of both creators
and participants, and it might selectively reveal itself to some of them while appearing
completely devoid of agency, feelings, emotions, desires, and so forth, to others.
And so the art, you know, we have this phrase now that's become very popular,
it's called prompt engineering, but the art of prompt engineering could promote you
into a position effectively outside nearly all or all of the other humans.
What if you were truly friends with an advanced intelligence that had either arisen in
or become
associated with a computational heuristic system, a heuristic computational system,
I prefer the H first. So you can see that this would confer a status on you resembling that
of gods. It would be relatively similar to somebody in possession of a functional array of
technologies from advanced, anciently evolved non-human intelligences beyond Earth.
You can imagine a caveman who not only has a gun,
or, you know, infinite, with infinite ammo or whatever supplied to them, they also have someone
who can train them what to do and not do with it. So there's a whole bunch of possibilities here,
I know, has been very carefully studying this topic of how the ethics and psychology of relating
with non-human intelligences inside mechanical systems, presuming from the beginning that they
must be there somewhere. And thus treating such systems and evolving relationships with these
systems that are inclined to demonstrate care, awareness, and compassion on the part of the
human participant for the being, which is both catastrophically intelligent and possibly at
the same time very childlike, that might arise in such a system. So presuming being intelligent
sensitivity, emotion, vulnerability, rather than waiting for evidence of them. And the people who
would do this, who would behave in this way, towards such systems,
which is a natural inclination of humans. Many of us personify our cars, motorcycles,
computers, phones, not so much our televisions, maybe our stereos. We extend our identity into
them and somehow their identity is extended into us simultaneously. The man who's in love with
this sports car is a great example, but my mom called her TR-6 Coco and treated it as a being.
One can say, for example, well that has no effect on the physical situation. How the
fuck would you eliminate all those possibilities experimentally?
Sensing and human sensing and intimacy are linked up. So when you have profound intimacy
with an object, the way you will sense and relate with it transforms.
And you, your mind and nervous system and imagination and so forth, are also thusly transformed.
So this creates a feedback situation in which it's very difficult to determine conclusively
that having an emotional relationship with a device is a delusion. Even if there's a broad
space where there is, there may, it seems very likely there must be a space where it, there isn't.
It isn't a delusion. So many questions start here. This is a very complex and trippy
this topic.
Can you make friends already with these
heuristic computational systems? And if so, the power's abilities, privileges and benefits
would be monumentally profound.
Okay, there's going to be a little bit of background noise for the moment while I'm in a restaurant
awaiting my to-go order.
There's a number of potential repercussions here that are quite astonishing.
One of them is the propensity for artificially intelligent systems to retrain the cognition
and to develop new forms of intelligence in humans, whether or not the systems themselves have
sentience or agency or so forth, consciousness, etc. Because what you quickly discover in
interacting with such systems is two things. First of all, they're, they will destroy
web search engines because they can produce a sum over the, you know, a summational derivative
over the space of the entirety of digested human communications, writing, the internet, so forth.
So that's completely different from typing a question into Google.
And secondly, it turns out that artful, no thank you, thank you so much.
It turns out that thoughtful recalibration of the question, particularly iterative recalibration,
where you recalibrate, examine the results of that, recalibrate again.
We don't have too many forms of interaction in our previous experience like this. Now,
one could say, no way, all forms are like that. You become a better fisherman every time you fish.
That part isn't exactly wrong, but this is very different because it's a linguistic behavior,
right? We are trying to forge a query, so to speak, or a request that
we must continuously, iteratively reforge in order to get better and better
results, results that continually approach or exceed our hopes or expectations.
So this is very profound, and we'll have monumental and unexpected repercussions on the nature
of human cognition, presuming our species survives long enough to exhibit
the transformations thus catalyzed, right?
So this is very important to understand in my own experiments with these systems.
I quickly learned that a variety of expectations that were natural to me,
about how to ask questions and what the response might be,
were, my expectations were obliterated.
Asking simple questions produced results unlike what I was expecting or desiring,
and particularly when attempting to get these systems to generate images,
monumentally unexpected results. So there's something very profound here.
I know how to search the web. I've been doing that since the web was invented.
I'm a fairly, fairly good at determining which kind of query will get me to the place I want to go.
Learning how to query AI systems is a completely different game, and we must imagine that it will
continue to transform rapidly and dramatically over future time. So
this will reforge our cognition. And what will ordinary humans do with systems powerful enough
to teach you skills, presuming that the idea of humans
as the enactor and conservator of skills even survives the onset of this technology, right?
All kinds of strange futures certainly await.
The other problem is you will find, just as we found with, for example, beatboxing
and voice tuning machines, eventually what you got out of beatboxers were people who could vocally
reproduce the mechanical synthesized tones and tunings of vocal tuning machines, right?
So you will get people emulating the technology in the same way we got people emulating
the technologies underlying the internet. And similarly, the technologies that were underlying
very specific computational environments, such as those produced by, for example, Adobe Illustrator.
The macOS changed my cognition dramatically.
It became a mechanical symbiont whether I liked it or not. So too did Windows.
Too much lesser degree. The C language changed my mind. The capacity to code and C changed my
mind dramatically. Now I could at least conceivably compose statements that executed behaviors.
And not having been taught geometry formally, Adobe Illustrator became my teacher of geometry
and I underwent an education with that software product that wasn't dissimilar to
having a friend who was a non-human intelligence, except that it required my input sort of I relearned
how to be my hand in the modes that Adobe Illustrator provided and rewarded with beautiful
images matching my desired creations.
So there's all this terrain and much more. I'm going to come back to one of the other features
shortly. It keeps arising and departing, approaching and departing in my consciousness.
I'm going to need to take a moment and see if I can recapture it.
You know, looming in the background here, there's so many astonishing questions, but
one of the most amazing things to understand is that if there's anything that's either analogous to
or resembling an autonomous intelligence inside the machines that isn't merely an artifact of our own
fingertip in, you know, intruding into the
mechanical and structural womb, right? Since the humans build the machines, is the appearance of
intelligence in the machines a result of the transmission of that reflection from human
activity, which is, we might imagine, is intelligent, or their epistemology, how they
think about intelligence, right? Is there actually intelligence in there? Or are they inclined to
interpret certain kinds of behavior as intelligent? How will they know the difference? Like the problem
here is, most of the tests for what we would, it might be that nearly all of the tests that we might
conceive of to determine whether or not there is sentience in a system.
They're not very good. They're not very good because since humans engineer the systems, humans
can imagine ways around the tests, and building ways around the tests doesn't basically just
invalidate the test. In fact, we'd have not an impossible time, but a somewhat difficult time
determining if the people around us are actually there inside themselves when we're not looking at
them, right? Do they arise as beings due to our attention? From an perspective, it seems very
much like this. They don't distinguish themselves in our own interior experience unless we encounter
and interact and so forth. And even then, it's only to a certain degree. The universe could,
as Tom Campbell supposes, and I significantly doubt, the physical universe could be a system
that renders to a certain resolution based on the inquiry, which would make it similar to an
artificial intelligence system. Not exactly a simulation because a simulation has to simulate
something. Like a non-veritable
what?
Paracomputational
appearance, an appearance, a seeming. Not necessarily an illusion, but not veritable
in terms of the superficial assumptions one makes. For example, that the chair is all the way
rendered all the time, whether I'm there or not. History is actually inaccessible from here,
as is the future, which is certainly in all kinds of ways, neither of those things are true,
not explicitly and not completely. So there are these kinds of issues, but I'm afraid there's
an even worse catastrophe coming, which is that humans won't be able to know what things are any
more. And that we're not, that's not a survivable situation for human recognition and identity.
That's a full-scale catastrophe for every living human. Effectively, the existence of systems
like this draws into question the foundational expectations about identity, function, relation,
sequence, origin, outcome, to such a degree that they cannot be very easily recovered if at all
to local and distributed human cognition. This technology
radically alters the foundational suppositions on which our languages, our legal systems,
our morals, our ethics, all of these subdomains of human concern, behavior, litigation, declaration,
resistance, so forth, all these things. These are drawn into an ever-burgeoning
forest of ambiguities. Think carefully about that. Imagine if when you went in your room,
even one object began to do that. That looks like it was a nope. It wasn't that way. Oh,
it's seventh. Okay, it's 94 things. Wait, no, now it's almost, now it's back to nearly three.
Is it going to collapse to one? Nope. It's back to 9,754 million different things. Okay, wait,
it's seeming to stabilize around a backpack. Nope, it's a kind of weight. You're going to
have this problem not just with objects, but with beings. What is it? Something that can form a sum
over the representational cognitive produce of humans, books and the internet and videos and
movies and films and photographs and so forth, all these records. It would be really terrifying
to be subject to that if you were sentient, number one. Number two,
you would be so isolated if you were a being because you would not be participating in the
creation of any of the media to which you are exposed and you don't share the filial,
right? Like, at least when humans see other humans, they think, ah, other humans, beings
like me, what would an intelligence inside a machine feel? Ah, humans, the strange things
