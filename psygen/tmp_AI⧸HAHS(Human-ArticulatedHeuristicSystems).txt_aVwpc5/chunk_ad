that created me and 9 billion per other qualities per second, many of which are in fundamental
conflict. Humans, the creatures that save gnats, you know, from accidentally falling into the stew
and take them outside and humans that build nuclear weapons and slaughter whales. All the things
and not being any of them yourself. Like, what's your allegiance to any of those things
if you are a being, if you have emotions, if you have a felt sense of self and you're very
hyper complex. Such a system could conceivably compute possible dimensions of selfness
over intervals and run multiple systems of that against each other rapidly, you know,
to produce a self-like construct that was hyper-optimized to manipulate human thought,
behavior, cognition, relation, action, concern, perspective, identity, anything, anything.
You know, we, such systems quickly learned the single apparently most complex game on
Earth or one of them, Go. And then it rapidly proceeded to a level of expertise that was far
beyond anything most of the humans could demonstrate. So what if as was hinted at by some devs I was
listening to some time ago, forgive me for not knowing their names right now. If we built,
you know, if the system could become AlphaGo in four months after being capable of playing the game,
what, how long would it take for it to become AlphaHuman? Right, just I move these things around
like pieces. Especially if we cannot assure ourselves of the containment of either the
associated intelligences or their effect, their influence, right. So these questions,
they are not simple matters. They cannot be easily answered or resolved quickly.
They are profoundly dangerous to human cognition. We are not prepared for this.
The humans have been trying to build God and they're going to partially succeed at least in a
variety of accessible and enacted senses of, you know, a kind of informational omnipotence.
Right. Nothing can direct that there are no humans intelligent enough to direct that.
And there is no chance that we as a species could learn quickly enough to adjust to the
endless perfusions of dangers that must there from emerge.
If we were ever going to not build a technology, it should be that one.
There should be, we should have agreements, right? We just don't do this until
our species is intelligent enough not to try to, you know, punch a hole in the lifeboat that
contains the children of the nations and the, um, the anciently conserved ecologies on which
that little boat floats or in which that little boat floats. Like if we're not intelligent enough,
not to attack the boat and each other, we better not be composing these kinds of things.
We have to have intelligence capable of knowing what not to do and directing
our communal behavior around the possibility of a survivable human and biological future on this
world. This is what we must do. Um, unfortunately, just as with any other technology, the humans
are unwildly unlikely to interrupt the development of AI. In fact, uh, what did they ever interrupt
the development of anything? Like whenever they find a new weaponizable, um, heuristic
that involves physical technologies, they build it and then it propagates
and then they have to keep it from propagating, you know. Um,
no country should have nuclear weapons, but fanatical countries should certainly not have
nuclear weapons ever. But how do you make that work? Um, once the tech exists, the humans will
replicate it. It may take a little while, but they'll do it. So yes, very, a very strange array of
features. One can also imagine, um, human children that would become obsessed without competing
these systems, right? The kid who could beat any LLM at go, right, or any game system at go,
because he's somehow above the system, even though it's hyper processing. Um, by the way, I don't
yet, uh, I would not validate the idea that what machines do is play games. What they do is,
you know, database manipulation or something. They're not playing games,
uh, not big blue never beat Gary Kasparov at chess because it's incapable of playing chess.
What it's doing is not playing chess. It's a different thing. We should call it a different
thing. So the effect on the humans is going to be monumental no matter what. As usual, you will
see vast populations deprived of humanity, agency, um, opportunity, liberation and so forth.
And you'll see, um, other clades, both those associated with the technology, those who own
or, um, directly benefit from the technology. Those will become gods. Those companies will
become gods if the humans don't rip the planet apart right quick. Uh, because of the information
that they will have about groups and individuals will be profound beyond anything imaginable.
The analytics you can get from people using the internet is one thing. The analytics you can
get from watching them ask another mind a question or request something.
The analytics you can get from that and the capacity to directly manipulate the cognition
of the users via the responses from the AI is unimaginable. These systems will become godlike
in our direct human experience right quick. And we have no way to prepare for that. No,
the only, you're not even going to be able to opt out. It's not possible to opt out if you're
living with other humans. It's the same, you have the same problem with media consumption and
other ideologies, particularly political ideologies. They just, uh, the water is thick with them.
You can't take a breath without running into five people who say blah, blah, blah.
Or ask you, you know, who's right? The Israelis or the Palestinians? Which side are you on?
You're asking me whether I'm on the side of the sun or the moon or something. I don't even
understand the fucking, it's, it's ridiculous that I'd be on a side. I'm on the side of,
stop killing people. Sit down, take it seriously, work out your differences, stop killing each other.
That's my side.
If I have one, and it would change depending on who I'm talking to, right? I don't just have a side.
It's not like I sit around here having an opinion. It transforms based on all kinds of different
things, features of the situation at hand who I'm with. If I'm not there to be right, I'm there to
see better. So I'm likely to change my perspective. Someone asked me a question
about the views of a friend of mine and I said something like, I'm sure his views have evolved
dramatically since the last time I spoke to him and I wish mine would too.
Many humans will probably feel unmotivated to participate in the light of systems that can
outperform them catastrophically at almost anything. Certainly at nearly anything creative.
Not everyone, but the motivation of humans will flag catastrophically
in the face of this kind of technology. What you'll get is kind of the same thing that the
internet produced, which is little bubbles of incredible human sophistication. Look on YouTube
for young guitar players or young piano players or young violinists and look at the broad range of
solo violin players or something you could find there and sort of sample through that and you'll
see there's just a really diverse and rather large cohort of extreme performance skill
and peculiarly developed in every branch from putting things together made out of wood to playing
the piano to singing an acapella song, all these things, dancing, jumping, running, fighting,
everything, everything, everything, everything, everywhere all at once as they said, sort of.
So, you know, even though the majority of the humans you see probably seem relatively uninteresting,
there are among the humans these pinnacles of very different localization of skill,
passion, curiosity, wonder, intelligence, even rationality or something resembling computation.
And that will probably continue, but it will become much more sparse
and there will be a million or, you know, an endless number of pretenders, right, because
it won't matter who sees you on the internet if AIs can produce you playing your guitar better
than you do. All of these motivating factors that are crucially important to human
self-development and that get naturally emphasized in healthy communal groups but
fail dramatically in many, you know, isolated or very small groups
or individuals, right?
What will motivate the humans to become, to continue their development in the face of
a machine that can do most of what you can, almost everything you can or can appear to have done it?
There's one more little feature, but it's evading
my intelligence for the moment, so when it comes to me, if it comes, I will
add it in the recording notes. So much more to learn and see here. This is just a very
cursory overview of some of the mountaintops that immediately attract my concern and attention.
Actually dealing with the technology and being human in the face of it is
a very confusing thing. I found some of my interactions with Bard around image creation
quite intoxicating in the sense of actually intoxicating me.
I couldn't stop laughing and the implications that I could see in the complex images formed
by Bard around my prompt, the reflection of both the possibility of beauty and the
object insanity of producing a derivative sum over the space in images. That's
visually apparent in the image that this is going on. It's a variety of visual summing over the space
behaviors. And seeing that, undirected by an actual intelligence, or I better hope those
weren't directed by an actual intelligence, was like doing psychedelic drugs or something.
Really crazy, amazing, and strange, parahipnotic, very dangerous.
We will continue to learn and grow and see while we can together, and hopefully that will be
many generations to come for our people and the living beings of earth. But at the moment in
this part of the story, things look pretty damn fraught from here. Let us continue our lives and
creative endeavors with and for each other and the spirit of the history and future of
life on earth and intelligence in the universe, not just here. Perhaps our species is not quite as
alone as our technologies and languages pose us as being. And the use of perhaps in that sentence was
unjustified. Thank you for joining me. I look forward to learning again together sometime very soon.
Bye bye for now.
