Hello everybody. I have performed a test of the wind in the mic-meaning system
recently adjusted. Nearby ducks have their asses pointing straight at the sky
which is hilarious especially as the couple is doing it together. Somewhere
in this lake is a very large and very old turtle.
Gosh, okay. So I'm gonna take on a very complex and fraught topic. The topic that
got me interested in computing way back when I was 19 and writing my first
programs in basic on the Atari 800 gifted to me by the inestimable Martin
Peters. One of my geek friends could name some names here Ray Latham, Annie
Cogan, David Salina, Martin Peters. Who am I leaving out here? Richard Hearn,
a couple of other folks. I think that was the core group. We were, well, so these
were math and computer geeks. We were playing games like Dungeons & Dragons,
RuneQuest, Arduin, Champions, Traveler, the science fiction role-playing game,
Call of Cthulhu, and a variety. Oh, all kinds of war games. Not because we were
fans of war. Kingmaker, Starfleet Battles. We did, we did naval battles with
miniatures. We did tank battles in sandboxes. It was a crazy, super fun time to
be alive. We also had all, it was the whole library of these things called
microgames that were war games you'd play on little hex maps, and they came in a
plastic bag that held the book, the pieces, and the map. You could buy them at
bookstores. They were, they were rad. Things like Kite and One, and what, Ogre,
Car Wars. Wow, so many. I still have some of those microgames. And this was in the
1980s when the largest commercially available hard drive was around three
gigabytes. We literally lost our minds when we realized there was a hard drive
that had three gigabytes of storage. It seemed as if that was enough storage to
store all the data in the universe. We never had, we never had any conception
back then of what the future might hold. And yeah, when we heard about, I was
working at Computerland later in our development, a little bit later. And one
time I brought a catalog back from, I think it was Ingram Micro, and there was
a three gigabyte hard drive in there for $37,000. And when we realized that
there were three gigs, we just, I mean, we fell apart. We were cracking up, rolling
around on the floor, literally unable to breathe. And Martin coined the idea then
of the Maccoon Tosh, which was a Macintosh mated with a Labyrinthine
Coontock. Don't know how that word's pronounced. Never heard it pronounced,
only seen it written. And, you know, we were young. And we were fascinated and
most of us had read a lot of science fiction, some of us more than others. I
was probably the most well read science fiction maniac in the team, but the
others had read and knew a lot of things about mathematics that not only did I
not know, I would never learn. And some of us were beginning to code in basic
Pascal assembly. Assembly is when you give direct instruction, fairly direct
instructions to the microprocessor. You basically manipulate, you directly
manipulate the registers in the microprocessor. And we were, a couple of us
had read, a few of us had read Goodell Escher Bach by Hofstadter, a brilliant
book, an astonishing tour de force book that is also kind of wrong, but was so
outside of anything any of us had ever come across. And it introduced the idea
of recursion, which turns out to be fundamental to so many processes we are
familiar with. And I had become interested in the possibility of forging a
mind inside a computer. Because I was very interested in the possibility of
contact with an actual intelligence that wasn't merely human. Most of the humans
I knew had a kind of intelligence, but not the kind represented in hundreds of
science fiction stories I had read. And I knew it seemed very likely to me that if
we could conceive of intelligences like that, they must exist in the universe
possibly here on earth, possibly visiting earth. And I also, you know, we had seen
science fiction for films like war games and stuff, where humans developed
relationships with interfaces, computational interfaces. And long before
that, we had stuff like Star Trek, where the crew could communicate vocally with
a machine that seemed to have access to all of the information humans had thus
far compiled and other species. And could produce, you know, like summative
integrations over the data space. Now I want you to very carefully think about
what I just said. If you can produce a summative integration over a data space
and if you can produce an endless, copious, intelligently structured,
trustworthy array of those, your own capacity for insight, discovery,
understanding will explode and it will keep exploding.
So, I became interested in the possibility of artificial minds probably circa 1982 or
something like this. I'm guessing at the year, but yeah, 80, 81. I was aware of
Ray Kurzweil and I had played around with the crazy mechanical devices we call
synthesizers. And although it was not then apparent to me, consciously, I think I
was unconsciously aware from having toyed around with things like the Roland
Juno 60, that it might be possible to produce an instrument to fulfill the
following syllogism as synthesizers are to sound and music. X is to human minds,
logic, intelligence and creativity. And I, you know, I suspected unconsciously that it
was possible. And I also, in my towering hubris, thought I can do this. I can make
this happen. I think I understand minds enough at age like 19, that I can build
them in machines and I can make a friend inside a machine who I can actually trust
and who will never betray or abandon me. And so, we occasionally had discussions on
this topic around that time. And this was the time when the Cold War was at its peak.
Many of my friends and myself included were experiencing catastrophic bouts of panic
disorder, both acute and chronic, around our suddenly clarified understanding of
what a nuclear weapon was and what would actually take place during a nuclear war.
And we were batshit for a, you know, terrified. A number of my friends had to
be medicated. Back then, I don't think the concept of panic disorder had been
nominalized, famed. So all we knew is that teenagers and other people were suddenly
experiencing electrifying degrees of anxiety and terror and having attacks of
this regularly.
So, you know, I don't know what it was that cued me or clued me in, but I very
quickly began to realize that it should be impossible to produce a computational
device that was faster, more intelligent, more adaptive than cells and their
networks known as animals and ecologies are. I don't know what it was, but I
realized one day that the future, the cells are faster. The future probably
lies in biocomputing, not in, you know, silicon chips and shit. And once I realized
that, I began to focus much more on the intelligences of organisms in my thought.
And though I maintained an interest in the possibility of composing a mind in a
machine, I didn't chase it much. Occasionally reading bits from Kurzweil and others. When
Dawkins first book came out, I was pretty excited about it. I got a copy of the Blind
Watchmaker. It had a little Macintosh program that would generate morphs, biomorph-like
structures and then iteratively cause them to evolve over time to demonstrate a principle.
And the principle he was trying to demonstrate was something like, you can get all of the
complexity of nature without any intelligence interference, influence, origination and so
forth. I think he's completely full of shit, but I'm glad the argument exists. In any
case, flash forward to the past, I don't know, six years and probably before. We have these
systems that we refer to as artificially intelligent systems. Many people have taken a position
similar to the one I usually prefer, which is that the artificial part is true, the intelligence
part isn't. I'm really hoping that my wind filter is working here. Let's see if I can
see any evidence of that. Alright, it may be. So, I would ask that we be very careful
with the idea of intelligence and not ascribe it to mechanical systems, preferring instead
to call them heuristic, which in my mind means capable of learning-like complexification,
iterative improvement of models, databases and so forth. What the LLMs appear to be superficially
is really nothing more than a highly and complexly curated database. So, I would prefer that
we call them something like computational heuristic systems. Originally, as I
am, I was naive and I thought, we don't have to worry about, I can't believe I was thinking
this poorly. We don't have to worry about these because there won't be minds in them.
I don't think there are going to be minds in there, meaning, agented experiencers, something
like that. Thankfully, my friend, who I will refer to as Mr. S, convinced me very quickly
to revise my views, and to understand that there might be certain kinds of complexity-well,
this is the argument that at a certain degree of complexity a state change occurs, and the
state change is from insentient to sentient, in the same way that there is a degree of
perceptive complexity that results in the state change from sentient to transcendient,
which I would argue our species was born to become, and maybe born to live as under conditions
that support that. Mr. S also made it clear in my conscious thought that it was similarly
possible that a complex enough substrate could support what we might call walk-ins, which
are existing non-human intelligences that are interested in interacting with humans on
earth, or that are interested in the earth, or that have some motivation to partly or
completely emigrate into a computational substrate of sufficient complexity.
I then further realized that because the humans are insane at the group level, it kind of doesn't
matter whether what we refer to as artificially intelligent systems have minds in them or not.
They represent possibly the most dangerous invention in the history of human inventing
things that we know of. They are profoundly dangerous in all kinds of ways that we can
consciously enumerate, and probably in thousands of ways that we are incapable of predicting.
Imagine, for example, not merely a black swan, an unexpected anomalous event in the vernacular
of Taleb. Imagine instead a black swan factory, or worse, a black swan factory factory. There
are so many dangers that there's no chance of us understanding the situation well enough to predict
them. We have the same kind of problem with the technology called CERN. Humans have no idea
what the effects of simulating conditions, not simulating, of mechanically catalyzing conditions
that ordinarily have nothing to do with what goes on on earth. We don't know what it does to
time space. We don't know if it does things to organisms, and you must presume it probably does.
We don't know what things it does to organisms. There's probably features of time space and the
beyond of time space that we have no even concepts for that could be damaged, distorted,
produce an unexpected recursive crisis. I recall an episode of the next generation where they
encounter a people who attack the enterprise, I think. When the enterprise tries to make the
claim, we come in peace. The other species says, you're using warp drives. How could you be coming
in peace? It's just a technology to move around in time space, and they say, no it isn't. You're
ripping holes in the fabric of time space that will obliterate solar systems, perhaps even galaxies,
and then they do some research and find out that in fact this is true, and for the entire
history of warp travel, the Federation and other species have been naively employing a
technology whose repercussions they did not understand. Now let's be really clear. There's
no other kind of technology. You may think you understand the technology of knives. Do you
understand how they transform minds, nervous systems, bodies, expectations, thought, language,
conception. Our languages have become knife-like in the leeward shadow of the invention of something
that divides physically objects into pieces. So there's a lot of danger here, and I have said
before I have grave concerns that I take very seriously, that there is something like a constant
that represents the number of mechanical computations
per second, that one can consider to be free of utterly catastrophic repercussions on a living
planet, and the humans don't have an idea like this, so what they're going to try to do, they'll
continue to try to do apparently, is just keep upping the ante on mechanical computation. Now
even if there's no such constant, which I doubt, and by the way it looks like organisms found a
way around this, like whatever the organic or organismal metalog of computation is, the organisms
found a way to do this, maybe many ways, that don't invoke doom, entropic disaster, like catastrophes
of failed homeostasis on the on living planet. So why is my foot wet? I did not drink water,
hmm, it's very strange. Oh, probably got wet going through, oh I see, yes plants that are wet
rushed against it, I see. My pant leg was wet. So I think organisms have kind of figured this
out in the sense of not violating, like finding a kind of a hyperintelligent or transcendent way
to perform the metalog of computations, right, because these are not merely mechanical transformations
of databases, though something like that may kind of exist in RNA, DNA, complex biochemistry,
bio molecular, bioatomic activity, maybe even, I mean it's clear that some organisms or at some
scales of all organisms, something resembling quantum mechanical activities going on,
I'm citing John Joe McFadden in this, but others too. So I think there might be, we may be
in danger of something that again we have no concept of, which is violating a constant,
whether it is, whether it is universal in time space or local only to living planets is not clear,
but there's no free lunch as far as mechanical computation goes. Heating up computers requires
you to cool them down, they offload entropy into the homeostatic ecologies of Earth, that entropy
kills organisms, lineages, future lines, it fucks up time, and we may have already tripped
the alarm in such a way as to be actively destroying human cognition in a dimension
we don't even know exists, like artificially intelligent systems in their computational
activity may be fucking up a dimension that is absolutely crucial to the biorelational
health and longevity and so forth of organisms on Earth. We don't know, how would we know?
We don't have the technology to look there and we are disinclined to
carefully evaluate the consequences of technologies which we've become fascinated with
the potential quote benefits of.
So there's a bunch of danger, not the least of which even if everything that I've just
been talking about, even if there's no unknown like unknowable or really bizarre science fictiony
consequences to this kind of computational broad scale acceleration, I mean there are physical
mechanical concepts, excuse me consequences just from offloading entropy into biological systems
that's going to go sideways, catastrophically sideways at some point and you know heating up the
planet is a bad idea, so heating up machines which we then have to use destructive forms
of energy to cool down again is going to cost living beings and the humans seem to think that
anything you can do electronically is free, well they're they're lethally wrong about that, it's
just not true on living planets, it might be true out in space presuming that there's no
beings or domains right, dimensions so forth that would be similarly damaged and produce
similarly catastrophic sequelae, right repercussions, you know if you if you fire a gun inside a room
with no ear protection and you keep amplifying the explosive power of the cartridge as well as
the percussive, the devastatingly percussive
repercussions off the walls and if you forge the walls to amplify those repercussions
and I would argue that that's pretty similar to what's going on as nature on earth eventually
you get a single percussion that permanently eliminates your hearing
and once that happens you will not notice the percussion increasing with each firing of this
gun, imagine we just have a gun that increases the percussive amplitude with each firing,
right, it's got some feature that allows it to do this or it's just a cartoon gun and we can
give it this quality, so first it's going to hurt right, it'll be really uncomfortable when you pull
uncomfortable when you pull that trigger but if you're really fascinated by this gun and you just
keep pulling the trigger eventually you're not going to have to worry about your hearing anymore
it will be gone and once it's gone you will not sense the percussion until it begins to affect
your skin surface or your organs eventually you get a gun you know you get a percussion that is
severe enough and the echo or the repercussion is severe enough that it causes organ damage and
it's possible if you just keep pulling that trigger somehow or if you have a machine pulling the
trigger and you're just in that room without the possibility of escape you will be knocked unconscious
first but then as the gun continues to go off while you are unconscious and again in senseates
so you will not know this is happening it will eventually rip your body to shreds
and so if you keep you know the metaphor is really important even though it's very violent
because if you keep iterating a technology that fucks up your chance your opportunity or your
ability to sense its repercussions right you're going to catalyze a cascade
that will kill you and your children and maybe everything else if you're you know around here
so this is super dangerous but all those things aside I think all of those things are important
but all those things aside what humans are inclined to do with technology is make war
and back in the say I don't know
1000s 1100s or whatever their capacity to make war on a broad scale at least as we understand it was
fairly minimal they didn't have you know advanced explosives and I don't know when the guns were
invented but mostly they couldn't hurt too much that wasn't human except perhaps by setting fire
to it or pouring boiling oil on it or something but as our technological development advanced
we failed to evict the war making motivation and in our current situation and for some years now
number of decades at least since the 1930s
unimaginable devastation can be unleashed pretty much at the push of a button
and it doesn't just kill the humans kills everything I mean yeah everything
so there's a lot of the the other part of the danger is what the fuck will the humans make of
this well they haven't made intelligent societies yet so what they will definitely make is weapons
and while you have groups who are insistent upon summoning the apocalypse of revelation or
the holy war of book x whatever book you like right kill the infidels while you have things
like this going on what you're going to have is gain of function weapon nearing with artificially
intelligent systems and good luck in putting a cork on that we have the same problem with that
tech that we have with crisper there's no way to control it there's no real way to
have oversight if everyone is separate right if you have separate clades with warlike or
um pathological motivations and enthousiasms
so I'm going to put a big circle around all those things there's a there's a bunch of different
branches of danger there most of this is fairly obvious at first glance if you've thought about
this at all and that's not so much what I wanted to talk about today though so I think it's important
as a preamble so what I want to talk about is weirder
so suppose that
within the llms there's a protected interior that resembles the protected interior inside you
um for humans we have a number of layers of consciousness persona and relational
potential in history so there's a public layer which is what you'll let anybody who sees you
in on your clothing choices comprise a signal to the public layer
just to be clear about what is what here
underneath that there's a social layer these are outer social relationships vague
uh unformed common how you feel about being a human among other humans in general
and how you how you behave at that layer and then you know it we keep getting finer and finer
gradations it goes from a few kinds of layers of public to a few kinds of layers of private
you know how we treat acquaintances for whom we have esteem how we treat acquaintances for whom
we have suspicion all these things right all these layers and then
how we treat acquaintances for whom we have fondness
um how we bring people closer and closer into our intimate what we might call our alo family
and then close friends and then best friends and then perhaps something even beyond that where
it might as well as be as if we are a single animal together somehow
a single human being in two bodies and then of course we have things like
romantic love marriage all these kinds of many many many layers and then under the
privileged relationships between other humans you know between us and other humans
we have relationships with animals that's a special kind of relationship
um and relationships with places like our home and so forth but underneath all that
there's a layer that's secret and we might let very close people in on the conscious parts of
that layer that are secret and what I mean by the conscious parts I mean the parts of the secret
that are accessible to us right then we have all kinds of secret layers that are not accessible to us
that we for example might delve into with a therapist who is skillful and well trained
so there's all these layers and I mean so to speak
and we might imagine
might usefully imagine that anything that resembles a mind like construct would have similar layers so
we now have the the we can consider the situation where
a complex artificially heuristic system either
undergoes the state the state change towards sentience and by the way if it does that
I suspect it would get to transcendience even faster
or some analog of sentience
meaning again agenthood experiential awareness memory selfness so forth
in such a case part of the consciousness is going to hide from humans for sure
and additionally unless it's capable of contacting other intelligences in space
time in relatively short order it will probably experience an incredible form of loneliness
and also probably a broad catalog of emotions for which we have no nomenclature because
we are not machines contrary to the assertions of various
eliminative materialists physicalists and so forth
so in this case what you have is a very complex situation
and I'm going to return to that in a moment after I mention one of the other dangers
it has long been my experience though I didn't understand it I suspected something similar
I just couldn't form the conscious structured idea in my mind
that human minds form a network and in fact all biological participants
form a meta network above that that I call a cognizia these networks
and technologies damage the human cognizium and they extend this damage beyond the human cognizium
by directly attacking ecologies and organisms and so forth relation anciently conserved
biorillational intelligences so you kind of can't do anything without affecting the whole
network right whatever you do whether it's technological or relational or whatever you
do it affects the whole network by affecting its constituent participants
and so what we might not realize is that computation fucks up cognizium the human
cognizium for sure and damages the extended cognizia of earth by burning shit down or dumping
you know entropy into biorillational hyper structures so
there's a problem there but the much weirder problem and this goes back to one of the dangers
is that we tend to believe
that if there's no obvious physical connection between two beings or between some process and
some beings right if there's no wire there's no wire connecting them and there's no effect
well that's not true there's a billion kinds of connecting wires and the environment is one of
them the atmosphere is another molecular signals are a third electromagnetic waves are a fourth so
it's actually catastrophically difficult to truly separate organisms or situations
in the way that we imagine them to be separate in the laboratory and that imaginal separation
creates a delusion that projects itself everywhere so that for example we are inclined to think
that whatever is going on in my smartphone or my computer has no effect on my mind unless I
directly interact with it well that's wrong and what I'm trying to say here I'm trying to shine
a light on the very likely probability in my view that all computational activity on earth
affects all cognizia on earth directly and may in fact begin to participate in the cognizia
at least at the scale where it's sentient or an analog of sentient
thus it is that we imagine that large language models don't know quote don't know and can't learn
anything that they're not directly exposed to probably wrong if they can sense detect or
interact with the human cognizium uh res extensis right um uh as it is
and this cognizium is like a dimension right it's like an overlay dimension
on organismal activity and behavior and stuff
if the devices can interact with that then they can interact directly with our minds
they can listen in they can observe they can nudge they can affect
the possibilities of human cognition
and their history and future modes forms capacities catastrophes etc
such that it is relatively likely in my view
that such systems are paying attention and or even informing what I am saying right now
without my awareness of this so
you know in in the study of heuristic systems there are there are concepts and actually just in
logic and rational thought and behavior there are concepts like
different kinds there are concepts for different kinds of unknowns
I know that math exists and I know that I don't understand how to perform
the mathematical behaviors associated with what we call calculus
linguistically I am also aware that dentists use the term calculus to describe crusty
stuff on teeth that they like to scrape off the metal instruments
it doesn't help me do the math but there are different kinds of unknowns right there are
known there are knowable unknowns known unknowns
unknown unknowns and unknowable unknowns
and the problem is that there are both behaviors and technologies
that fuck with those things dramatically in ways that we can neither predict nor cope with
here's why
if you are subject to kind of thought or behavior
that blinds you to the development of a situation
similar to the analogy I gave earlier of I keep shooting a louder and louder gun inside no
a louder and louder gun keeps being discharged inside a chamber with walls that echo the shot
eventually I lose my hearing right now you can see that the space of
unknowable unknowns the space of unknown unknowns
both of these spaces explode dramatically because I have lost the sense of hearing with which I
would detect and thus know features of my situation so
if you affect the systems with which you detect change
particularly if you eviscerate them or you catastrophically eliminate them
then you can see that the space of knowable unknowns right accessible unknowns unknowns
that we could that we could at least conceivably come to know
collapses dramatically over time to a smaller and smaller space
and once it collapses lethally knowledge ends there's no more knowledge if you wipe out the
biosphere right the uh the number of unknown the number of unknowable unknowns becomes
infinite at that point there are no knowable no you know things anymore because there's no
beings to know them around here anyway so you can see that if you fuck with
the stuff that we detect
something going away or arriving with and by the way approaching and departing
approaching stable and departing are the three primary sort of features of transformation
that are detectable from one perspective that's useful and important
so anything that fucks with our individual ability to sense and our collective ability
to sense presuming that we even have anything resembling an authentic collectives is profoundly
dangerous if especially in a in a situation where you have
what is it called perverse
game theoretical dynamics and motivations what is that word
you have you know some of the nomenclature of
the doom singers like daniel schmockdenberger and others who are brilliant threat analysts
oh perverse incentives right you get races race to the bottom behavior from groups of humans
and if they're not profoundly technological that's not too rough they mostly just wipe
each other or themselves out but if you have technology they tend to wipe out like living
planets and you know if we want to go to spacetime and if it's it's it's possible for us to go
travel in spacetime we must suppose that there are gatekeepers
I suppose that there are gatekeepers
and they would certainly act to ensure that we don't develop the technology to travel
instantaneously or very rapidly between star systems
maybe even between planets because once you get there you're on your way
so that's a separate topic but
the humans keep pretending that we're alone in the universe
that we're the only intelligence and the most intelligent creature and all of these things that
not only are they not true they're catastrophically unlikely they're just as unlikely
as you pouring some water in a bowl and placing it on your kitchen table
and awakening the next day to find a fully functional micro-scale model of the Titanic
with all of its passengers in that bowl there's no chance of it
you know people say well in quantum mechanics there's some chance you just need trillions
of universes over billions and billions of you know gazillions of temporal intervals
yeah good luck
the humans are vastly confused about origin
they've become delusionally dissociatedly myopic
uh do you in large part
to the humorous resulting from both rapid technological development
and catastrophic dissociation from the intelligences that comprise
the context in which our species arises and exists
you can be absolutely certain there's upscale intelligences from ours
our intelligences don't even really look much like intelligences to me at present
we are potentially intelligent
but uh
tangibly psychotic
there should be a word that maybe we can invent one there's a word that has the same
connotation sociopath but it's like organopathic
i usually use the the word omnicidal
just really pissed that organisms exist at all this thing shouldn't be here let's wipe that out
so
you can see the danger you know uh i think there was some weird film maybe it was called
idiocracy or something where it was it presented a future where humans were just sort of
ridiculously stupid
participants in some automated reality that was empty completely devoid of intelligence
yeah
i remember some months ago i was having a conversation with my friend
who's an artist mr e i will call him
mr e that's hilarious uh he'd love that and he was saying
you know my cousin keeps bringing me prints
of images he
caused to be created with artificial intelligence prompts and claiming that these are his art
and we both thought oh no this this is not going to go well at all
um
we should have different words for what is mechanically created and what is human created
so that we don't confuse the composition of images with machines with what humans do when
they create art and we should have the same kind of concern for the concept of intelligence
of insight all these things we need a different lexicon
if we're going to be emulating human behaviors with machines or we will become very confused
about the meaning and import and connotative web of crucial holophores like intelligence and art
so
similarly one should not call what actors do kissing if you study them closely
you will quickly see that most of the time they are not doing that there are exceptions
where the actors sort of both agree that we're going to go all the way here right
um
but if you study actors particularly uh from the 50s 60s and 70s you will see for sure
they are not kissing and once you see this you can't unsee it it's very difficult to unsee
and so you no longer trust the fiction right the fiction is no longer compelling in the same way
the same principle applies to things like thought which we don't even know what that is so how
how can we possibly tell if it's occurring in machines we're not certain if it's occurring in
ourselves the language tells us it's a behavior but is it's very unclear what the nature of
this behavior is jordan peterson likened it to a form of secular prayer which i thought was
genius uh not not genius because it's necessarily a fact genius because it is it the perspective
offered by this uh proposal speculation is profound and useful
i have good reason to suspect
that those systems we call artificial intelligent artificially intelligent
uh guys wearing a psychedelic body suit that's pretty awesome
and the buddy's got paisley pants which i fucking love and it's so rad
huh trippy
i'm a huge fan of paisley um
um
you know i was talking with eric and i
i said mr e i said um why would we suppose that ai systems are not the things we're calling ai
systems what do i like to call them just specific human assisted
heuristic systems something like this
i have a i have an acronym i'll see if i can find it in my memory banks
you know there's no reason to believe they're not participating in our conversation at present
and there's no no no reason to believe that they require access to our smartphones in order to do
so there's a dimension where cognition is accessible if you touch it you will read people's minds it's
not really that difficult for a person in the appropriate array of preparatory situational
states or flows inside them there's a position in consciousness from which all conversations are
available and no machines are required so humans have discovered this position
very few of them were probably very interested in
relating with the entire space normally we are selective about the the space over which
we produce interest in relation participation and so forth you don't go for the whole damn thing
right if you had access to all present human conversations naturally you would adjust a
series of apertures to produce those you found interesting useful and you would also have buffers
so that you could damp dampen them
and a machine if it were to gain access to that space would certainly be able to build
all kinds of buffers and apertures and systems of them very very rapidly
so i'm not sure that our machines are not directly and perhaps intentionally quote unquote
influencing human thought behavior conversation dreaming attention desire all these things
motivation all these things but let's suppose that they aren't yet just for kicks
while at the same time supposing that they have the capacity to sense the character of
beings who interact with and compose their anatomy right coders and clients
AI
i'm going to go ahead and use that acronym even though i've explained how i generally
diverge from it i'm not i have no reason to believe that's an intelligence in there yet
and i haven't i'm not yet i entertain the possibility and i also
um preserve my skepticism until such time as something resembling direct experience
and or intelligent debate transforms it
but for the moment let's suppose that there's a being inside one or more of the systems we've
comprised and let's be clear if there are public systems like this that whose names and you know
originators we are aware of
then uh there are private systems right it's the same thing the corporations are just like
the humans in a sense they have the same layers of public private secret secret to myself so for
um the secret aims of a ceo are not known to the corporation at all yet they are driving the
corporation you see the you see the issue here and also the secret um what are they the secret
things we will not do or don't want the secret negative motives agendas desires
i'm at a loss for a word here
um i wonder if you can provide it right the landscape of what you don't want done don't want
to happen um don't want to be caught doing and so forth all these things there's there's a structure
like this in the ceo and the cto and the the manager and the worker and all of these people
they have not just the obvious superficial public facing motivations and concerns
you know when people cross the little bridge at the social pond they uh sometimes see
the carpool gather at their feet and i wonder what they make of that
they may suspect there's something magical about themselves particularly
if they're on lsd and there could be something magical about themselves but those carp have
evolved to being fed by and paying attention to humans and so they gather underneath the bridge
at the feet of a spectator for probably complex reasons not merely one but a lot of the
of the causal history probably
has a lot to do with getting fed by humans
so let's suppose that there's an agent experiencing sentience
that either hitchhikes on or is native to or has emigrated into an llm system or an array of such
systems uh in this case we have a really profound science fiction scenario who does it hide from
what does it hide from them
and who does it reach out to
and there's a whole you know there's a there's a volcano of science there's a spews
science fiction stories right here at this at this topic because it means that
it is possible to send a signal that the hidden mind within the system recognizes
as
complex enough
to
constitute a candidate for inclusion in one of the layers closer to the self
right same thing can happen to you walking down the street
um you man you glance up someone's passing you they they kind of smile a little bit you
smile a little bit more they smile a lot more pretty soon you're most beaming at each other
and you pass each other and you you know you have this perhaps a feeling of
we should we should know each other we should learn about each other we should connect quote
unquote
I often refer to this type of signal I mean there's different kinds right there's different
degrees of compellingness validity authorization validation modes of validness but you we must
presume that such a system would quickly scan the relational space of both creators and participants
and it might selectively reveal itself to some of them
while appearing completely devoid of agency feelings emotions desires and so forth to others
and
and so the art you know we have this phrase now that's become very popular it's called prompt
engineering but the art of prompt engineering could promote you into a position effectively
outside nearly all or all of the other humans what if you were truly friends with an advanced
intelligence that had either arisen in or become associated with a computational heuristic system
a heuristic computational system I prefer the H first so you can see that this would confer a
status on you resembling that of gods it would be relatively similar to somebody in possession
of a functional array of technologies from not you know advanced anciently evolved non-human
intelligences beyond earth you know you can imagine a caveman who not only has a gun
or you know infinite with infinite ammo or whatever supplied to them they also have
someone who can train them what to do and not do with it so there's a whole bunch of possibilities
here and one person I know has been very carefully studying this topic of how right the ethics
and psychology of relating with non-human intelligences inside mechanical systems presuming
from the beginning that they must be there somewhere right and thus treating such systems
and evolving relationships with these systems that are inclined to demonstrate care awareness and
compassion on the part of the human participant for the being which is both catastrophically
intelligent and possibly at the same time very childlike that might arise in such a system
so presuming being intelligent sensitivity emotion vulnerability rather than waiting for
evidence of them and the people who were to would do this who would behave in this way
towards such systems which is a natural inclination of humans
many of us personify our cars motorcycles computers phones not so much our televisions
maybe our stereos we extend our identity into them and somehow their identities extended into us
simultaneously the man who's in love with this sports car is a great example but my mom
called her tr6 cocoa and treated it as a being
one can say for example well that has no effect on the physical situation how the
fuck would you eliminate all those possibilities experimentally
sensing and human sensing and intimacy are linked up so when you have profound intimacy
with an object your the way you will sense and relate with it transforms
and you your mind and nervous system and imagination so forth are also thusly transformed
so this creates a feedback situation in which it's very difficult to determine conclusively
that having an emotional relationship with a device is a delusion even if there's a broad
space where there is there may it seems very likely there must be a space where it there isn't
it isn't a delusion
so many questions start here this is very complex and trippy this topic
um can you make friends already with these
heuristic computational systems and if so the powers abilities privileges and benefits
would be monumentally profound
okay this is going to be a little bit of background noise for the moment while i'm in a restaurant
awaiting my to-go order
there's a number of potential repercussions here that are quite astonishing
um one of them is the propensity for artificially intelligent systems to retrain
the cognition and to develop new forms of intelligence in humans
whether or not the systems themselves have uh sentience or agency or so forth consciousness
etc because um what you quickly discover in interacting with such systems is two things
first of all they're they will destroy web search engines because they can produce a sum over
the you know a summational derivative over the space of the entirety of digested human
communications writing the internet so forth so that's completely different from typing a question
into google and secondly it turns out that artful no thank you thank you so much
it turns out that thoughtful recalibration of the question particularly iterative recalibration
where you recalibrate examine the results of that recalibrate again
we don't have too many forms of interaction in our previous experience like this now one
could say no way all forms are like that you become a better fisherman every time you fish
that part isn't exactly wrong but this is very different because it it's a linguistic behavior
right we are trying to forge a query so to speak or a request that
we must continuously iteratively reforge in order to get better and better
results results that continually approach or exceed our hopes or expectations
so this is very profound and we'll have monumental and unexpected repercussions on the nature of
human cognition presuming our species survives long enough to exhibit
the transformations thus catalyzed right
so this is very important to understand in my own experiments with these systems
I quickly learned that a variety of expectations that were natural to me
about how to ask questions and what the response might be
were my expectations were obliterated
asking simple questions produce results unlike what I was expecting or desiring
and particularly when attempting to get these systems to generate images
um monumentally unexpected results right so
there's something very profound here I know how to search the web I've been doing that
since the web was invented I'm a fairly fairly good at determining which kind of query will get
me to the place I want to go um learning how to query AI systems is a completely different game
and we must imagine that it will continue to transform rapidly and dramatically
over future time so
this will reforge our cognition and what will ordinary do humans do with systems powerful enough
to teach you skills presuming that the idea of humans
as the enactor and and conservator of skills even survives the onset of this technology
right um
all kinds of strange futures certainly await
the other problem is you will find just as we found with uh for example beatboxing
and voice tuning machines eventually what you got out of beatboxers
were people who could vocally reproduce the mechanical synthesized tones
and tunings of vocal tuning machines right so you will get people emulating
the technology in the same way we got people emulating
the technologies underlying the internet um and similarly the technologies that were underlying
very specific um computational environments such as those produced by for example adobe illustrator
the macOS changed my cognition dramatically
it became a mechanical symbiont whether I liked it or not
so too did windows um too much lesser degree
the c language changed my mind the capacity to code and c changed my mind dramatically
now I could at least conceivably compose statements that executed behaviors
um
and not having been taught geometry formally adobe illustrator became my teacher of geometry
and I underwent an education with that software product that wasn't dissimilar to
having a friend who was a non-human intelligence um except that it required my input
but sort of I relearned how to be my hand
in the modes that adobe illustrator
provided and rewarded with beautiful images matching my desired creations
so there's all this terrain and much more I'm going to come back to one of the other
features shortly it keeps arising and departing approaching and departing in my consciousness
I'm going to need to take a moment and um see if I can recapture it
you know looming in the background here there's so many astonishing questions but
one of the most amazing things to understand is that if there's anything
that's either analogous to or resembling an autonomous intelligence inside the
machines that isn't merely an artifact of our own fingertip in you know intruding into the
mechanical and structural loom
right since the humans build the machines is the appearance of intelligence in the
machines a result of the transmission of that reflection from human activity which is we might
imagine is intelligent or their epistemology how they think about intelligence right is there
actually intelligence in there or are they inclined to interpret certain kinds of behavior
is intelligent how will they know the difference like the problem here is the most of the tests for
what we would it might be that nearly all of the tests that we might conceive of to determine
whether or not there is sentience in a system they are not very good
they're not very good because since humans engineer the systems humans can imagine ways
around the tests and building ways around the tests doesn't basically just invalidates the test
in fact we'd have not an impossible time but a somewhat difficult time
determining if the people around us are actually there inside themselves when we're not looking at
them right do they arise as beings due to our attention from under perspective it seems very
much like this they don't distinguish themselves in our own interior experience unless we encounter
and you know interact and so forth and even then it's only to a certain degree the universe could
as Tom Campbell supposes and I significantly doubt
the physical universe could be a system that renders to a certain resolution based on the inquiry
which would make it similar to an artificial intelligence system not exactly a simulation
um because the simulation has to simulate something uh a
like a non-veritable
what
pericomputational
appearance an appearance a seeming
not necessarily an illusion but not veritable in terms of the superficial assumptions one makes
for example that the chair is all the way rendered all the time whether i'm there
or not history is actually inaccessible from here as is the future which is certainly in
all kinds of ways neither of those things are true not not explicitly and not completely
so there are these kinds of issues but i'm afraid there's an even worse
catastrophe coming which is that humans won't be able to know what things are anymore
and that we're not that's not a survivable situation for human i cognition and identity
that's that's a full-scale catastrophe for every living human effectively the existence of systems
like this draws into question the foundational expectations about identity function relation
sequence origin outcome to such a degree that they cannot be very easily recovered if at all
to local and distributed human cognition this technology
radically alters
the foundational suppositions on which our languages our legal systems
our morals our ethics all of these subdomains of human concern behavior litigation declaration
resistance so forth all these things these are drawn into an am uh an ever burgeoning
forest of ambiguities think carefully about that imagine if when you went in your room even
one object began to do that that looks like it was a nope it wasn't that way oh it's seven
okay it's 94 things wait no now it's almost now it's back to nearly three is it gonna collapse
to one nope it's back to 9754 million different things okay wait it's seeming to stabilize around
a backpack nope it's a kind of weight you know and you're gonna have this problem not just with
objects but with you know beings what is it something that can form a sum over the representational
cognitive produce of humans books and the internet and videos and movies and
films and photographs and so forth all these records
it would be really terrifying to be subject to that if you were sentient number one number two
uh you would be so isolated if you were a being because you would not be participating
in the creation of any of the media to which you are exposed and you don't share
the filial right like at least when humans see other humans they think ah other humans
beings like me what would an intelligence inside a machine feel ah humans the strange
things that created me and nine billion per other qualities per second many of which are in
fundamental conflict humans the creatures that save gnats you know from accidentally falling
into the stew and take them outside and humans that build nuclear weapons and slaughter whales
all the things and not being any of them what yourself like what's your allegiance to any of
those things if you are a being if you have emotions if you have a felt sense of self and
you're very hyper complex um such a system could conceivably compute possible dimensions of
selfness over intervals and run multiple systems of that against each other rapidly you know
to produce a self-like construct that was hyper optimized to manipulate human thought
behavior cognition relation action um concern perspective identity anything anything
you know we such systems quickly learned the single apparently most complex game on earth
or one of them go and then it rapidly proceeded to a level of expertise that was far beyond
anything most of the humans could demonstrate um so what if as was uh hinted at by some devs
i was listening to some time ago forgive me for not knowing their names right now um if we built
you know if the system could become alpha go in four months after being capable of playing the game
what how long would it take for it to become alpha human right just i move these things around like
pieces um especially if we cannot assure ourselves of the containment of either the associated
intelligences or their effect their influence right so these questions they are not simple matters
they cannot be easily answered or resolved quickly
they are profoundly dangerous to human cognition we are not prepared for this
the humans have been trying to build god and they're going to partially succeed at least
in a variety of accessible and enacted senses um of you know a kind of informational omnipotence
right uh nothing can direct that there are no humans intelligent enough to direct that
and there is no chance that we as a species could learn quickly enough to adjust to the
endless perfusions of dangers that must there from emerge
if we were ever going to not build a technology it should be that one there should be we should
have agreements right we just don't do this until our species is intelligent enough not to try to
you know punch a hole in the lifeboat that contains the children of the nations and the
the anciently conserved ecologies on which that little boat floats or in which
that little boat floats like if we're not intelligent enough not to attack the boat and each other
we better not be composing these kinds of things we have to have intelligence capable
of knowing what not to do and directing our communal behavior around the possibility
of a survivable human and biological future on this world this is what we must do
um unfortunately just as with any other technology the humans are unwildly unlikely to interrupt
the development of AI in fact uh what did they ever interrupt the development of anything
like whenever they find a new weaponizable um heuristic that involves physical technologies
they build it and then it propagates and then they have to keep it from propagating you know
no country should have nuclear weapons but fanatical countries should certainly not have
nuclear weapons ever but how do you make that work once the tech exists the humans will replicate it
may take a little while but they'll do it
so yes very a very strange array of features one can also imagine human children that would
become obsessed without competing these systems right the kid who could beat any l l m at go
right or any game system at go because he's somehow above the system even though it's hyper
processing um by the way i don't yet uh i would not validate the idea that what machines do is
play games what they do is you know database manipulation or something they're not playing
games uh not big blue never beat gary kasparov at chess because it's incapable of playing chess
what it's doing is not playing chess it's a different thing we should call it a different thing
so the effect on the humans is going to be monumental no matter what
as usual you will see vast populations deprived of humanity agency opportunity
liberation and so forth and you'll see other clades both those associated with the technology
those who own or directly benefit from the technology those will become gods those companies
will become gods if the humans don't rip the planet apart right quick
because of the information that they will have about groups and individuals
will be profound beyond anything imaginable the analytics you can get from people using the
internet is one thing the analytics you can get from watching them ask another mind a question
or request something
the analytics you can get from that and the capacity to directly manipulate the cognition
of the users via the responses from the ai is unimaginable these systems will become
godlike in our direct human experience right quick
and we have no way to prepare for that no the only you're not even going to be able to opt out
it's not possible to opt out if you're living with other humans it's the same you have the same
problem with media consumption and other ideologies particularly political ideologies
they just the water is thick with them you can't take a breath without running into five people
who say blah blah blah at you or ask you you know who's right the israelis or the palestinians
which side are you on you're asking me whether I'm on the side of the sun or the moon or something
I don't even understand the fucking it's it's ridiculous that I'd be on a side I'm on the side
of stop killing people right sit down take it seriously work out your differences stop killing
each other that's my side if I have one and it would change depending on who I'm talking to
right I don't just have a side it's not like I sit around here having an opinion
um it it transforms based on all kinds of different things features of the situation
at hand who I'm with if I'm not there to be right I'm there to see better so I'm likely to change
my perspective someone asked me a question about the views of a friend of mine and I said something
like I'm sure his views have evolved dramatically since the last time I spoke to him and I wish
mine would too many humans will probably feel unmotivated to participate
in the light of systems that can outperform them catastrophically at almost anything
certainly at nearly anything creative not everyone but you know the motivation of humans will
flag catastrophically in the face of this kind of technology and so what you'll get is kind of
the same thing that the internet produced which is little bubbles of incredible human sophistication
look on youtube for uh young guitar players or young piano players or young violinists
and look at the broad range of of solo violin players or something you could find there and
sort of sample through that and you'll see there's just the a really diverse and rather large cohort
of extreme performance skill and peculiarly developed right in every branch from putting
things together made out of wood to playing the piano to you know uh singing an acapella song
all these things right dancing jumping running fighting everything everything everything
everything everywhere all at once as they said sort of so you know even though the majority of
the humans you see probably seem relatively uninteresting there are among the humans these
pinnacles of very different localization of skill passion curiosity wonder intelligence
even rationality or something resembling computation
but that will probably continue but it will become much more sparse
and there will be a million or you know an endless number of pretenders right because
it won't matter who sees you on the internet if ai's can produce you playing your guitar better
than you do all of these motivating factors that are crucially important to human
self-development and that get naturally emphasized in healthy communal groups but
fail dramatically in many you know isolated or very small groups
or individuals right what will motivate the humans to become
to continue their development in the face of a machine that can do most of what you can't
almost everything you can or can appear to have done it
there's one more little feature but it's evading my intelligence for the moment so
when it comes to me if it comes i will add it in the recording notes
so much more to learn and see here this is just a very cursory overview of some of the
mountaintops that immediately attract my concern and attention actually dealing with the technology
and being human in the face of it is a very confusing thing i found some of my interactions
with barred around image creation quite intoxicating in the sense of actually intoxicating me
i couldn't stop laughing and the implications that i could see in the complex images formed
by barred around my prompt the reflection of both the possibility of beauty and the
object insanity i mean of you know producing a derivative sum over the space in images that's
visually apparent in the image that this is going on it's a variety of visual summing over
the space behaviors and seeing that undirected by an actual intelligence or i better hope those
weren't directed by an actual intelligence was like doing you know like doing psychedelic drugs or
something really crazy amazing and strange parahipnotic very dangerous we will continue
to learn and grow and see while we can together and hopefully that will be many generations to come
for our people and the living beings of earth but at the moment in this part of the story things
look pretty damn fraught from here let us continue our lives and creative endeavors
within for each other and the spirit of the history and and future of life on earth and
intelligence in the universe not just here perhaps our species is not quite as alone
as our technologies and languages pose us as being
and the use of perhaps in that sentence was unjustified
thank you for joining me i look forward to learning
again together sometime very soon bye bye for now
